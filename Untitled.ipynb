{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60af7171-c7b9-45a6-b030-2166177cff3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = key  # reemplaza con tu clave real si es necesario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe10f3ef-0321-4ec6-9b3e-7c4d77ccfee0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: langchain-community 0.3.21\n",
      "Uninstalling langchain-community-0.3.21:\n",
      "  Successfully uninstalled langchain-community-0.3.21\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall -y langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "210dea32-54f6-40ef-b8a2-c5266cfaf923",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.75.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: Apache-2.0\n",
      "Location: /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages\n",
      "Requires: sniffio, tqdm, httpx, pydantic, anyio, jiter, distro, typing-extensions\n",
      "Required-by: langchain-openai\n",
      "---\n",
      "Name: langchain\n",
      "Version: 0.3.23\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages\n",
      "Requires: SQLAlchemy, langchain-core, async-timeout, PyYAML, langsmith, requests, pydantic, langchain-text-splitters\n",
      "Required-by: \n",
      "---\n",
      "Name: langgraph\n",
      "Version: 0.3.31\n",
      "Summary: Building stateful, multi-actor applications with LLMs\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages\n",
      "Requires: langgraph-checkpoint, xxhash, langgraph-prebuilt, langgraph-sdk, langchain-core\n",
      "Required-by: \n",
      "---\n",
      "Name: langchain-openai\n",
      "Version: 0.3.14\n",
      "Summary: An integration package connecting OpenAI and LangChain\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages\n",
      "Requires: openai, tiktoken, langchain-core\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show openai langchain langgraph langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee16ecf-89d8-4dbf-8f1f-5a7c051d6e38",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### üìò **Cap√≠tulo 7. Agentes II**\n",
    "\n",
    "El Cap√≠tulo 6 present√≥ la arquitectura de agentes, la m√°s poderosa de las arquitecturas de LLM que hemos visto hasta ahora. Es dif√≠cil exagerar el potencial de esta combinaci√≥n de encadenamiento de pensamientos, uso de herramientas y bucles.\n",
    "\n",
    "Este cap√≠tulo analiza dos extensiones de la arquitectura de agentes que mejoran el rendimiento para algunos casos de uso:\n",
    "\n",
    "---\n",
    "\n",
    "#### **Reflexi√≥n**\n",
    "\n",
    "Tomando otra p√°gina del repertorio de patrones de pensamiento humano, esto trata sobre darle a tu aplicaci√≥n con LLM la oportunidad de analizar sus propias salidas y elecciones pasadas, junto con la capacidad de recordar reflexiones de iteraciones anteriores.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Multi-agente**\n",
    "\n",
    "De manera similar a c√≥mo un equipo puede lograr m√°s que una sola persona, hay problemas que pueden abordarse mejor con equipos de agentes LLM.\n",
    "\n",
    "---\n",
    "\n",
    "Comencemos con la reflexi√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Reflexi√≥n**\n",
    "\n",
    "Una t√©cnica de prompts que a√∫n no hemos cubierto es la reflexi√≥n (tambi√©n conocida como autocr√≠tica). La reflexi√≥n es la creaci√≥n de un bucle entre un prompt generador y un prompt revisor. Esto refleja el proceso de creaci√≥n de muchos artefactos generados por humanos, como este cap√≠tulo que est√°s leyendo ahora, el cual es el resultado de un ida y vuelta entre los autores, revisores y editor, hasta que todos est√©n satisfechos con el producto final.\n",
    "\n",
    "Como muchas de las t√©cnicas de prompts que hemos visto hasta ahora, la reflexi√≥n se puede combinar con otras t√©cnicas, como el encadenamiento de pensamientos (chain-of-thought) y el uso de herramientas. En esta secci√≥n, veremos la reflexi√≥n de forma aislada.\n",
    "\n",
    "Se puede trazar un paralelo con los modos de pensamiento humano conocidos como Sistema 1 (reactivo o instintivo) y Sistema 2 (met√≥dico y reflexivo), introducidos por primera vez por Daniel Kahneman en su libro *Thinking, Fast and Slow* (Farrar, Straus and Giroux, 2011). Cuando se aplica correctamente, la autocr√≠tica puede ayudar a que las aplicaciones con LLM se acerquen a algo que se asemeje al comportamiento del Sistema 2 (Figura 7-1).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Figura 7-1. Pensamiento del Sistema 1 y del Sistema 2**\n",
    "\n",
    "Implementaremos la reflexi√≥n como un grafo con dos nodos: **generar** y **reflexionar**. Este grafo tendr√° la tarea de escribir ensayos de tres p√°rrafos, con el nodo `generate` escribiendo o revisando borradores del ensayo, y `reflect` escribiendo una cr√≠tica para informar la siguiente revisi√≥n. Ejecutaremos el bucle un n√∫mero fijo de veces, pero una variaci√≥n de esta t√©cnica ser√≠a permitir que el nodo de reflexi√≥n decida cu√°ndo terminar. Veamos c√≥mo se ve:\n",
    "\n",
    "---\n",
    "\n",
    "### üêç C√≥digo Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f839b0d-7dbd-42fd-970d-61495eb8cf02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c555a4-dfea-4b0b-8414-2e8bbf5eca5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# Definimos el estado del grafo, que es una lista de mensajes\n",
    "class Estado(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "# Prompt para generar ensayos\n",
    "prompt_generar = SystemMessage(\n",
    "    \"\"\"Eres un asistente de ensayos encargado de escribir excelentes ensayos \n",
    "    de 3 p√°rrafos.\"\"\"\n",
    "    \"Genera el mejor ensayo posible para la solicitud del usuario.\"\n",
    "    \"\"\"Si el usuario proporciona una cr√≠tica, responde con una versi√≥n \n",
    "    revisada de tus intentos anteriores.\"\"\"\n",
    ")\n",
    "\n",
    "# Nodo de generaci√≥n\n",
    "def generar(estado: Estado) -> Estado:\n",
    "    respuesta = model.invoke([prompt_generar] + estado[\"messages\"])\n",
    "    return {\"messages\": [respuesta]}\n",
    "\n",
    "# Prompt para reflexionar (criticar el ensayo)\n",
    "prompt_reflexion = SystemMessage(\n",
    "    \"\"\"Eres un profesor que califica un ensayo. Genera cr√≠ticas y \n",
    "    recomendaciones para la entrega del usuario.\"\"\"\n",
    "    \"\"\"Proporciona recomendaciones detalladas, incluyendo solicitudes sobre \n",
    "    longitud, profundidad, estilo, etc.\"\"\"\n",
    ")\n",
    "\n",
    "# Nodo de reflexi√≥n\n",
    "def reflexionar(estado: Estado) -> Estado:\n",
    "    # Invertimos los mensajes para que el LLM reflexione sobre su propia salida\n",
    "    cls_map = {AIMessage: HumanMessage, HumanMessage: AIMessage}\n",
    "    # Primer mensaje es la solicitud original del usuario; se mantiene igual\n",
    "    traducido = [prompt_reflexion, estado[\"messages\"][0]] + [\n",
    "        cls_map[msg.__class__](content=msg.content) \n",
    "        for msg in estado[\"messages\"][1:]\n",
    "    ]\n",
    "    respuesta = model.invoke(traducido)\n",
    "    # Tratamos la salida como retroalimentaci√≥n humana para el generador\n",
    "    return {\"messages\": [HumanMessage(content=respuesta.content)]}\n",
    "\n",
    "# Condici√≥n para detener el bucle\n",
    "def deberia_continuar(estado: Estado):\n",
    "    if len(estado[\"messages\"]) > 6:\n",
    "        # Terminamos despu√©s de 3 iteraciones, cada una con 2 mensajes\n",
    "        return END\n",
    "    else:\n",
    "        return \"reflect\"\n",
    "\n",
    "# Construcci√≥n del grafo\n",
    "construccion = StateGraph(Estado)\n",
    "construccion.add_node(\"generate\", generar)\n",
    "construccion.add_node(\"reflect\", reflexionar)\n",
    "construccion.add_edge(START, \"generate\")\n",
    "construccion.add_conditional_edges(\"generate\", deberia_continuar)\n",
    "construccion.add_edge(\"reflect\", \"generate\")\n",
    "\n",
    "# Compilar el grafo\n",
    "grafo = construccion.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ccb963-503b-45d7-9725-0a496e93b8fd",
   "metadata": {},
   "source": [
    "Este bloque de c√≥digo define el **nodo de reflexi√≥n** dentro de un flujo donde un LLM escribe y luego se revisa a s√≠ mismo. Vamos l√≠nea por l√≠nea:\n",
    "\n",
    "---\n",
    "\n",
    "### `def reflexionar(estado: Estado) -> Estado:`\n",
    "Define una funci√≥n llamada `reflexionar` que recibe un diccionario con estado (`Estado`), y devuelve otro estado.\n",
    "\n",
    "---\n",
    "\n",
    "### `cls_map = {AIMessage: HumanMessage, HumanMessage: AIMessage}`\n",
    "Esta l√≠nea define un **mapa de clases inversas**. Su prop√≥sito es **intercambiar los roles** de los mensajes:\n",
    "- Lo que fue generado por el LLM (`AIMessage`), ahora ser√° tratado como si lo hubiera dicho un humano (`HumanMessage`).\n",
    "- Y viceversa (aunque en este caso, eso no se usa).\n",
    "\n",
    "Este \"truco\" hace que el modelo analice su propia respuesta como si **otro humano lo hubiera dicho**, promoviendo una reflexi√≥n m√°s efectiva.\n",
    "\n",
    "---\n",
    "\n",
    "### `traducido = [prompt_reflexion, estado[\"messages\"][0]] + [ ... ]`\n",
    "Aqu√≠ se est√° construyendo una nueva lista de mensajes:\n",
    "1. Primero, se a√±ade el mensaje del sistema `prompt_reflexion`, que le dice al modelo que act√∫e como maestro que eval√∫a un ensayo.\n",
    "2. Luego se agrega el **mensaje original del usuario**, sin cambios (√≠ndice 0).\n",
    "3. Despu√©s, **todos los mensajes posteriores** (respuestas del LLM, principalmente) se transforman a su clase contraria, usando `cls_map`.\n",
    "\n",
    "Esto es como decirle al modelo:  \n",
    "*\"Aqu√≠ est√° la conversaci√≥n, pero trata lo que t√∫ dijiste como si lo hubiera dicho otra persona y ahora eval√∫alo.\"*\n",
    "\n",
    "---\n",
    "\n",
    "### `respuesta = model.invoke(traducido)`\n",
    "Aqu√≠ se invoca al modelo con esa conversaci√≥n transformada, para que genere su **cr√≠tica o retroalimentaci√≥n**.\n",
    "\n",
    "---\n",
    "\n",
    "### `return {\"messages\": [HumanMessage(content=respuesta.content)]}`\n",
    "Finalmente, se encapsula la cr√≠tica como si fuera un mensaje **humano** (simulando que viene de un revisor), y se devuelve como nuevo estado. Esto lo usar√° el generador para mejorar su ensayo en la siguiente iteraci√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "### ¬øPara qu√© sirve todo esto?\n",
    "Este nodo permite que el modelo **aprenda de s√≠ mismo en cada iteraci√≥n**, generando mejores resultados conforme reflexiona y revisa sus respuestas anteriores. Es como un ciclo de borradores y correcciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35100f04-56e5-4cdb-bf79-1d0f3ee7f617",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Resultado final:\n",
      "\n",
      "üôã Humano:\n",
      "Escribe un ensayo sobre el impacto de la inteligencia artificial en la educaci√≥n\n",
      "\n",
      "ü§ñ AI:\n",
      "La inteligencia artificial (IA) ha revolucionado numerosos aspectos de nuestras vidas, y la educaci√≥n no es una excepci√≥n. El impacto de la IA en la educaci√≥n es profundo y prometedor. En primer lugar, la IA ha permitido la personalizaci√≥n del aprendizaje, adaptando el contenido educativo a las necesidades individuales de cada estudiante. A trav√©s de algoritmos inteligentes, se pueden crear programas educativos individualizados que maximizan el potencial de cada alumno, permiti√©ndoles avanzar a su propio ritmo y en √°reas donde m√°s lo necesitan.\n",
      "\n",
      "En segundo lugar, la IA ha facilitado la accesibilidad a la educaci√≥n, rompiendo barreras geogr√°ficas y econ√≥micas. Plataformas educativas basadas en IA ofrecen cursos en l√≠nea gratuitos o a precios accesibles, permitiendo que personas de todo el mundo puedan acceder a una educaci√≥n de calidad. Adem√°s, la IA ha contribuido al desarrollo de tecnolog√≠as como los asistentes virtuales y los chatbots educativos, que brindan apoyo constante a los estudiantes fuera del aula y los gu√≠an en su proceso de aprendizaje.\n",
      "\n",
      "Por √∫ltimo, aunque la IA presenta grandes beneficios en la educaci√≥n, tambi√©n plantea desaf√≠os √©ticos y sociales. Es fundamental garantizar la transparencia en el uso de la IA en el √°mbito educativo, as√≠ como fomentar la educaci√≥n digital y la alfabetizaci√≥n tecnol√≥gica para que los estudiantes puedan comprender y cuestionar el papel de la IA en su aprendizaje. En resumen, la inteligencia artificial est√° transformando la educaci√≥n, ofreciendo nuevas oportunidades y desaf√≠os que debemos abordar de manera responsable y equitativa.\n",
      "\n",
      "üôã Humano:\n",
      "Tu ensayo ofrece una visi√≥n general interesante sobre el impacto de la inteligencia artificial en la educaci√≥n. Aqu√≠ tienes algunas cr√≠ticas y recomendaciones para mejorar tu entrega:\n",
      "\n",
      "1. **Extensi√≥n del ensayo**: Aunque tu ensayo aborda el tema de manera concisa, ser√≠a beneficioso profundizar m√°s en cada punto que mencionas. Considera expandir tus ideas con ejemplos concretos, datos estad√≠sticos o estudios de caso para respaldar tus argumentos y hacer que tu ensayo sea m√°s persuasivo.\n",
      "\n",
      "2. **Coherencia y fluidez**: Aseg√∫rate de estructurar tu ensayo de manera l√≥gica para que los lectores puedan seguir f√°cilmente tu argumento. Utiliza conectores y palabras de transici√≥n para que tu ensayo fluya de manera coherente de una idea a otra.\n",
      "\n",
      "3. **Perspectiva cr√≠tica**: Aunque mencionas brevemente los desaf√≠os √©ticos y sociales que plantea la IA en la educaci√≥n, ser√≠a √∫til profundizar en estos aspectos. Explora m√°s a fondo c√≥mo la IA puede afectar la privacidad de los estudiantes, la equidad en el acceso a la educaci√≥n y la p√©rdida de empleos en el sector educativo debido a la automatizaci√≥n.\n",
      "\n",
      "4. **Conclusi√≥n s√≥lida**: Tu conclusi√≥n es un buen resumen de tus puntos principales, pero podr√≠a ser m√°s contundente. Podr√≠as incluir una reflexi√≥n final que resuma tus argumentos clave y plantee preguntas que inviten a la reflexi√≥n sobre el futuro de la educaci√≥n con la IA.\n",
      "\n",
      "5. **Estilo de escritura**: Intenta mantener un tono acad√©mico en tu ensayo y evita el lenguaje informal. Adem√°s, aseg√∫rate de revisar la redacci√≥n y la gram√°tica para mejorar la claridad y la cohesi√≥n de tu texto.\n",
      "\n",
      "En general, tu ensayo tiene una base s√≥lida, pero hay √°reas donde puedes expandir y mejorar tu an√°lisis para hacerlo m√°s completo y persuasivo. Sigue trabajando en el desarrollo de tus ideas y en la organizaci√≥n de tu ensayo para construir un argumento m√°s s√≥lido y convincente. ¬°Buena suerte!\n",
      "\n",
      "ü§ñ AI:\n",
      "La inteligencia artificial (IA) est√° dejando una huella indeleble en el campo de la educaci√≥n, transformando significativamente la forma en que aprendemos y ense√±amos. Uno de los impactos m√°s notables de la IA en la educaci√≥n es la personalizaci√≥n del aprendizaje. A trav√©s de algoritmos inteligentes, se pueden crear programas educativos adaptados a las necesidades individuales de cada estudiante, permiti√©ndoles avanzar a su propio ritmo y profundizar en √°reas espec√≠ficas de inter√©s. Por ejemplo, plataformas como Khan Academy utilizan la IA para recomendar contenido educativo personalizado con el objetivo de maximizar el potencial de cada alumno.\n",
      "\n",
      "Adem√°s, la IA ha facilitado la accesibilidad a la educaci√≥n al romper barreras geogr√°ficas y econ√≥micas. Plataformas en l√≠nea como Coursera o edX ofrecen una amplia gama de cursos gratuitos o a precios accesibles, permitiendo que personas de todo el mundo puedan acceder a una educaci√≥n de calidad desde la comodidad de sus hogares. Asimismo, la IA ha dado lugar a tecnolog√≠as innovadoras como los asistentes virtuales y los chatbots educativos, que brindan apoyo personalizado a los estudiantes fuera del aula y los gu√≠an en su proceso de aprendizaje de manera interactiva y eficaz.\n",
      "\n",
      "No obstante, a pesar de los beneficios evidentes de la IA en la educaci√≥n, tambi√©n plantea desaf√≠os √©ticos y sociales que no podemos pasar por alto. Es fundamental abordar la cuesti√≥n de la transparencia en el uso de la IA en el √°mbito educativo, as√≠ como garantizar la equidad en el acceso y la privacidad de los datos de los estudiantes. Adem√°s, la automatizaci√≥n generada por la IA podr√≠a tener repercusiones en el empleo en el sector educativo, lo que requiere una reflexi√≥n cr√≠tica sobre c√≥mo preparar a los educadores para los cambios tecnol√≥gicos en curso. En conclusi√≥n, la inteligencia artificial ha revolucionado la educaci√≥n, ofreciendo nuevas posibilidades y desaf√≠os que deben ser abordados de manera equitativa y responsable para garantizar un futuro educativo inclusivo y sostenible.\n",
      "\n",
      "üôã Humano:\n",
      "¬°Excelente trabajo en tu ensayo! Has abordado de manera clara y concisa el impacto de la inteligencia artificial en la educaci√≥n, destacando tanto los beneficios como los desaf√≠os que presenta esta tecnolog√≠a. Aqu√≠ tienes algunas recomendaciones para mejorar tu entrega:\n",
      "\n",
      "1. **Profundidad en los ejemplos y evidencia**: Aunque mencionas ejemplos relevantes, como Khan Academy y Coursera, podr√≠as profundizar un poco m√°s en c√≥mo espec√≠ficamente utilizan la IA para personalizar el aprendizaje y mejorar la accesibilidad educativa. Agregar ejemplos concretos y datos estad√≠sticos fortalecer√° tus argumentos y brindar√° mayor credibilidad a tu ensayo.\n",
      "\n",
      "2. **An√°lisis cr√≠tico**: Aunque tocas brevemente los desaf√≠os √©ticos y sociales de la IA en la educaci√≥n, podr√≠as expandir esta secci√≥n. Profundiza en c√≥mo la falta de transparencia podr√≠a afectar a los estudiantes y educadores, y c√≥mo se podr√≠an abordar las preocupaciones relacionadas con la privacidad de los datos en entornos educativos impulsados por la IA.\n",
      "\n",
      "3. **Perspectiva del futuro**: Ser√≠a beneficioso incluir una secci√≥n que explore posibles escenarios futuros en el √°mbito educativo con la creciente influencia de la IA. ¬øC√≥mo crees que la IA continuar√° transformando la educaci√≥n en los pr√≥ximos a√±os? La especulaci√≥n informada podr√≠a enriquecer tu an√°lisis y agregar un componente de anticipaci√≥n.\n",
      "\n",
      "4. **Conexiones m√°s s√≥lidas entre los p√°rrafos**: Aseg√∫rate de que haya una transici√≥n suave entre tus ideas y p√°rrafos para que tu ensayo fluya de manera coherente y l√≥gica. Utiliza conectores y frases de transici√≥n para guiar al lector a lo largo de tu argumento de manera clara.\n",
      "\n",
      "En general, tu ensayo es s√≥lido y bien estructurado. Contin√∫a profundizando en tus argumentos, respald√°ndolos con ejemplos concretos y evidencia s√≥lida para hacer que tu ensayo sea a√∫n m√°s convincente y completo. ¬°Sigue as√≠!\n",
      "\n",
      "ü§ñ AI:\n",
      "La inteligencia artificial (IA) est√° transformando el panorama educativo de manera significativa, ofreciendo beneficios sustanciales pero tambi√©n planteando desaf√≠os importantes que deben abordarse con responsabilidad. La personalizaci√≥n del aprendizaje es uno de los puntos m√°s destacados del impacto de la IA en la educaci√≥n. Plataformas como Khan Academy utilizan algoritmos inteligentes para adaptar el contenido educativo a las necesidades individuales de cada estudiante, permiti√©ndoles avanzar a su propio ritmo y profundizar en √°reas espec√≠ficas. Esta personalizaci√≥n no solo mejora la experiencia educativa, sino que tambi√©n maximiza el potencial de aprendizaje de cada alumno, brindando una educaci√≥n m√°s efectiva y enfocada.\n",
      "\n",
      "Adem√°s, la accesibilidad a la educaci√≥n se ha visto notablemente mejorada gracias a la IA. Plataformas en l√≠nea como Coursera y edX ofrecen una amplia gama de cursos gratuitos o a precios accesibles, eliminando barreras geogr√°ficas y econ√≥micas para el aprendizaje. La IA tambi√©n ha dado lugar a innovaciones como los asistentes virtuales y chatbots educativos, que proporcionan apoyo personalizado a los estudiantes y los gu√≠an de manera interactiva en su proceso de aprendizaje. Estas herramientas tecnol√≥gicas no solo ampl√≠an el acceso a la educaci√≥n, sino que tambi√©n mejoran la experiencia de aprendizaje de los estudiantes al ofrecer un acompa√±amiento constante y adaptado a sus necesidades individuales.\n",
      "\n",
      "Sin embargo, a pesar de los evidentes beneficios de la IA en la educaci√≥n, surgen desaf√≠os √©ticos y sociales que requieren una atenci√≥n especial. Es crucial abordar la cuesti√≥n de la transparencia en el uso de la IA en el √°mbito educativo, garantizar la equidad en el acceso a la educaci√≥n y proteger la privacidad de los datos de los estudiantes. Asimismo, la automatizaci√≥n generada por la IA plantea interrogantes sobre el futuro del empleo en el sector educativo, lo que destaca la necesidad de una reflexi√≥n cr√≠tica sobre c√≥mo preparar a educadores y estudiantes para los cambios tecnol√≥gicos en curso. En resumen, la inteligencia artificial est√° transformando el panorama educativo de manera profunda, ofreciendo nuevas oportunidades y desaf√≠os que deben ser abordados con conciencia y equidad para garantizar un futuro educativo inclusivo y sostenible.\n",
      "\n",
      "üôã Humano:\n",
      "¬°Excelente ensayo sobre el impacto de la inteligencia artificial en la educaci√≥n! Has desarrollado de manera clara y estructurada los beneficios y desaf√≠os que presenta la IA en este √°mbito. Aqu√≠ tienes algunas sugerencias para enriquecer a√∫n m√°s tu trabajo:\n",
      "\n",
      "1. **Refuerzo de argumentos con evidencia adicional**: Aunque has mencionado plataformas como Khan Academy, Coursera y edX como ejemplos de c√≥mo la IA ha mejorado la personalizaci√≥n y accesibilidad educativa, podr√≠as ampliar tus ejemplos con casos concretos de c√≥mo estas plataformas utilizan la IA en la pr√°ctica. Incluir datos espec√≠ficos y estudios de casos reforzar√° tus argumentos y brindar√° m√°s solidez a tu ensayo.\n",
      "\n",
      "2. **Exploraci√≥n de perspectivas cr√≠ticas adicionales**: Para enriquecer tu an√°lisis, podr√≠as considerar incluir otras perspectivas cr√≠ticas sobre el impacto de la IA en la educaci√≥n. Por ejemplo, podr√≠as profundizar en c√≥mo la IA podr√≠a afectar la relaci√≥n entre estudiantes y docentes, el desarrollo de habilidades socioemocionales o la participaci√≥n de los padres en el proceso educativo en un entorno digitalizado.\n",
      "\n",
      "3. **Propuesta de soluciones o recomendaciones**: Ser√≠a √∫til finalizar tu ensayo con posibles soluciones o recomendaciones para abordar los desaf√≠os √©ticos y sociales planteados por la IA en la educaci√≥n. ¬øQu√© medidas espec√≠ficas podr√≠an tomarse para garantizar la transparencia, equidad y protecci√≥n de datos en la implementaci√≥n de la IA en las aulas?\n",
      "\n",
      "4. **Vocabulario y redacci√≥n**: Tu ensayo est√° bien redactado, pero aseg√∫rate de mantener un estilo acad√©mico formal y de utilizar un vocabulario preciso y claro en todo momento. Revisa la coherencia en t√©rminos de voz y tiempos verbales para garantizar una comunicaci√≥n fluida.\n",
      "\n",
      "En general, has elaborado un ensayo s√≥lido y convincente. Contin√∫a desarrollando tus ideas, respald√°ndolas con evidencia s√≥lida y considerando diversas perspectivas para ofrecer un an√°lisis completo sobre el tema. ¬°Sigue adelante con tu excelente trabajo!\n",
      "\n",
      "ü§ñ AI:\n",
      "La inteligencia artificial (IA) ha dejado una marca significativa en el campo educativo, abriendo nuevas posibilidades y desaf√≠os que requieren una consideraci√≥n cuidadosa. Uno de los impactos m√°s destacados de la IA en la educaci√≥n es la personalizaci√≥n del aprendizaje. Plataformas como Khan Academy utilizan algoritmos inteligentes para adaptar el contenido educativo a las necesidades espec√≠ficas de cada alumno, permiti√©ndoles avanzar a su propio ritmo y profundizar en √°reas de mayor inter√©s. Este enfoque personalizado no solo mejora la efectividad del aprendizaje, sino que tambi√©n empodera a los estudiantes al ofrecerles un camino educativo √∫nico y ajustado a sus necesidades individuales.\n",
      "\n",
      "Adem√°s, la IA ha revolucionado la accesibilidad a la educaci√≥n al eliminar barreras geogr√°ficas y econ√≥micas. Plataformas en l√≠nea como Coursera y edX ofrecen una variedad de cursos gratuitos o a precios asequibles, ampliando el acceso a la educaci√≥n a una audiencia global. Adem√°s, la IA ha dado lugar a tecnolog√≠as innovadoras como los asistentes virtuales y chatbots educativos, que brindan apoyo personalizado a los alumnos y los gu√≠an de manera interactiva en su proceso de aprendizaje. Estas herramientas tecnol√≥gicas no solo enriquecen la experiencia educativa, sino que tambi√©n fomentan la autonom√≠a y la motivaci√≥n de los estudiantes al brindarles un acompa√±amiento eficaz y adaptado a sus necesidades individuales.\n",
      "\n",
      "A pesar de los beneficios evidentes que aporta la IA a la educaci√≥n, tambi√©n plantea desaf√≠os √©ticos y sociales que requieren atenci√≥n. Es esencial abordar la cuesti√≥n de la transparencia en el uso de la IA en el √°mbito educativo, garantizar la equidad en el acceso a la educaci√≥n y proteger la privacidad de los datos de los estudiantes. Asimismo, la automatizaci√≥n generada por la IA puede plantear interrogantes sobre el futuro del empleo en el sector educativo, lo que destaca la importancia de preparar a educadores y estudiantes para los cambios tecnol√≥gicos en curso. En resumen, la inteligencia artificial est√° remodelando el panorama educativo de manera profunda y din√°mica, ofreciendo oportunidades significativas si se abordan los desaf√≠os de manera √©tica y equitativa para construir un futuro educativo inclusivo y sostenible.\n"
     ]
    }
   ],
   "source": [
    "# --- Ejecutar ejemplo ---\n",
    "entrada_inicial = {\n",
    "    \"messages\": [HumanMessage(content=\"Escribe un ensayo sobre el impacto de la inteligencia artificial en la educaci√≥n\")]\n",
    "}\n",
    "\n",
    "estado_final = grafo.invoke(entrada_inicial)\n",
    "\n",
    "# --- Mostrar resultado ---\n",
    "print(\"üìù Resultado final:\")\n",
    "for msg in estado_final[\"messages\"]:\n",
    "    tipo = \"ü§ñ AI\" if isinstance(msg, AIMessage) else \"üôã Humano\"\n",
    "    print(f\"\\n{tipo}:\\n{msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bb2458-9f14-4666-b4e0-32fcefe7fe29",
   "metadata": {},
   "source": [
    "\n",
    "Observa c√≥mo el nodo de reflexi√≥n enga√±a al LLM haci√©ndole creer que est√° criticando ensayos escritos por el usuario. Y, de forma paralela, se hace que el nodo de generaci√≥n piense que la cr√≠tica proviene del usuario. Este enga√±o es necesario porque los LLMs entrenados para di√°logo est√°n entrenados con pares de mensajes humano-IA, por lo que una secuencia con muchos mensajes del mismo participante dar√≠a como resultado un rendimiento deficiente.\n",
    "\n",
    "Un detalle m√°s a tener en cuenta: podr√≠as, a primera vista, esperar que el final ocurra despu√©s de un paso de revisi√≥n, pero en esta arquitectura tenemos un n√∫mero **fijo** de iteraciones en el ciclo generar-reflexionar; por lo tanto, terminamos despu√©s de generar (para que el √∫ltimo conjunto de revisiones solicitadas sea atendido). Una variaci√≥n de esta arquitectura permitir√≠a que el paso de reflexi√≥n decidiera cu√°ndo terminar el proceso (una vez que ya no tuviera m√°s comentarios).\n",
    "\n",
    "Veamos c√≥mo se ve una de las cr√≠ticas:\n",
    "\n",
    "---\n",
    "\n",
    "Este tipo simple de reflexi√≥n puede, en ocasiones, mejorar el rendimiento al darle al LLM m√∫ltiples intentos de refinar su salida y al permitir que el nodo de reflexi√≥n adopte una **personalidad distinta** mientras critica el resultado.\n",
    "\n",
    "Hay varias posibles variaciones de esta arquitectura. Por ejemplo, podr√≠amos combinar el paso de reflexi√≥n con la arquitectura de agentes del Cap√≠tulo 6, a√±adi√©ndolo como el √∫ltimo nodo justo antes de enviar la salida al usuario. Esto har√≠a que la cr√≠tica pareciera provenir del usuario y le dar√≠a a la aplicaci√≥n una oportunidad de mejorar su salida final sin intervenci√≥n directa del usuario. Obviamente, este enfoque implicar√≠a una mayor **latencia**.\n",
    "\n",
    "En ciertos casos de uso, podr√≠a ser √∫til fundamentar la cr√≠tica con informaci√≥n externa. Por ejemplo, si estuvieras construyendo un agente de generaci√≥n de c√≥digo, podr√≠as tener un paso antes de reflexionar que ejecute el c√≥digo a trav√©s de un *linter* o *compilador* y reporte cualquier error como entrada para la reflexi√≥n.\n",
    "\n",
    "üí° **CONSEJO**  \n",
    "Siempre que este enfoque sea posible, te recomendamos encarecidamente probarlo, ya que probablemente aumentar√° la calidad del resultado final.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3daa798-7854-4ce7-871f-c5525cf6fc4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Si solo quieres ver el **√∫ltimo mensaje generado** (el resultado final del ciclo de generaci√≥n-reflexi√≥n), puedes modificar la √∫ltima parte del c√≥digo as√≠:\n",
    "\n",
    "```python\n",
    "# Mostrar solo el √∫ltimo mensaje (el m√°s reciente)\n",
    "ultimo_mensaje = estado_final[\"messages\"][-1]\n",
    "\n",
    "if isinstance(ultimo_mensaje, AIMessage):\n",
    "    print(\"üìù √öltimo mensaje de la IA:\\n\")\n",
    "else:\n",
    "    print(\"üôã √öltimo mensaje del 'usuario':\\n\")\n",
    "\n",
    "print(ultimo_mensaje.content)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Esto imprimir√° √∫nicamente el contenido final, que dependiendo del n√∫mero de iteraciones ser√°:\n",
    "\n",
    "- Un ensayo si la √∫ltima acci√≥n fue de la IA (`AIMessage`)\n",
    "- Una cr√≠tica si termin√≥ en reflexi√≥n (`HumanMessage`)\n",
    "\n",
    "> üí° Tip: En el flujo original, el ciclo siempre termina despu√©s de una **generaci√≥n**, as√≠ que el √∫ltimo mensaje ser√° una respuesta final mejorada del asistente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3815f1d-f798-4d30-a144-160db3e3a569",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù √öltimo mensaje de la IA:\n",
      "\n",
      "La inteligencia artificial (IA) ha dejado una marca significativa en el campo educativo, abriendo nuevas posibilidades y desaf√≠os que requieren una consideraci√≥n cuidadosa. Uno de los impactos m√°s destacados de la IA en la educaci√≥n es la personalizaci√≥n del aprendizaje. Plataformas como Khan Academy utilizan algoritmos inteligentes para adaptar el contenido educativo a las necesidades espec√≠ficas de cada alumno, permiti√©ndoles avanzar a su propio ritmo y profundizar en √°reas de mayor inter√©s. Este enfoque personalizado no solo mejora la efectividad del aprendizaje, sino que tambi√©n empodera a los estudiantes al ofrecerles un camino educativo √∫nico y ajustado a sus necesidades individuales.\n",
      "\n",
      "Adem√°s, la IA ha revolucionado la accesibilidad a la educaci√≥n al eliminar barreras geogr√°ficas y econ√≥micas. Plataformas en l√≠nea como Coursera y edX ofrecen una variedad de cursos gratuitos o a precios asequibles, ampliando el acceso a la educaci√≥n a una audiencia global. Adem√°s, la IA ha dado lugar a tecnolog√≠as innovadoras como los asistentes virtuales y chatbots educativos, que brindan apoyo personalizado a los alumnos y los gu√≠an de manera interactiva en su proceso de aprendizaje. Estas herramientas tecnol√≥gicas no solo enriquecen la experiencia educativa, sino que tambi√©n fomentan la autonom√≠a y la motivaci√≥n de los estudiantes al brindarles un acompa√±amiento eficaz y adaptado a sus necesidades individuales.\n",
      "\n",
      "A pesar de los beneficios evidentes que aporta la IA a la educaci√≥n, tambi√©n plantea desaf√≠os √©ticos y sociales que requieren atenci√≥n. Es esencial abordar la cuesti√≥n de la transparencia en el uso de la IA en el √°mbito educativo, garantizar la equidad en el acceso a la educaci√≥n y proteger la privacidad de los datos de los estudiantes. Asimismo, la automatizaci√≥n generada por la IA puede plantear interrogantes sobre el futuro del empleo en el sector educativo, lo que destaca la importancia de preparar a educadores y estudiantes para los cambios tecnol√≥gicos en curso. En resumen, la inteligencia artificial est√° remodelando el panorama educativo de manera profunda y din√°mica, ofreciendo oportunidades significativas si se abordan los desaf√≠os de manera √©tica y equitativa para construir un futuro educativo inclusivo y sostenible.\n"
     ]
    }
   ],
   "source": [
    "# Mostrar solo el √∫ltimo mensaje (el m√°s reciente)\n",
    "ultimo_mensaje = estado_final[\"messages\"][-1]\n",
    "\n",
    "if isinstance(ultimo_mensaje, AIMessage):\n",
    "    print(\"üìù √öltimo mensaje de la IA:\\n\")\n",
    "else:\n",
    "    print(\"üôã √öltimo mensaje del 'usuario':\\n\")\n",
    "\n",
    "print(ultimo_mensaje.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e0436-42f9-480a-a886-25934e7c6d39",
   "metadata": {
    "tags": []
   },
   "source": [
    "Aqu√≠ va la traducci√≥n con los comentarios y cadenas de texto en el c√≥digo tambi√©n traducidos, pero sin tocar variables ni estructuras, como pediste:\n",
    "\n",
    "---\n",
    "\n",
    "### Subgrafos en LangGraph\n",
    "\n",
    "Antes de adentrarnos en arquitecturas multi-agente, veamos un concepto t√©cnico importante en LangGraph que las hace posibles. Los subgrafos son grafos que se utilizan como parte de otro grafo. Aqu√≠ algunos casos de uso para los subgrafos:\n",
    "\n",
    "- Construcci√≥n de sistemas multi-agente (se discute en la siguiente secci√≥n).\n",
    "- Cuando quieres reutilizar un conjunto de nodos en m√∫ltiples grafos, puedes definirlos una vez en un subgrafo y luego usarlos en varios grafos principales.\n",
    "- Cuando diferentes equipos necesitan trabajar en diferentes partes del grafo de manera independiente, puedes definir cada parte como un subgrafo, y mientras se respete la interfaz del subgrafo (los esquemas de entrada y salida), el grafo principal puede construirse sin conocer los detalles del subgrafo.\n",
    "\n",
    "Hay dos maneras de a√±adir nodos de subgrafo a un grafo principal:\n",
    "\n",
    "**1. Agregar un nodo que llame directamente al subgrafo**  \n",
    "Esto es √∫til cuando el grafo principal y el subgrafo comparten claves de estado, y no necesitas transformar el estado ni al entrar ni al salir.\n",
    "\n",
    "**2. Agregar un nodo con una funci√≥n que invoque el subgrafo**  \n",
    "Esto es √∫til cuando el grafo principal y el subgrafo tienen diferentes esquemas de estado, y necesitas transformar el estado antes o despu√©s de llamar al subgrafo.\n",
    "\n",
    "Veamos cada una por separado.\n",
    "\n",
    "---\n",
    "\n",
    "### Llamando a un Subgrafo Directamente\n",
    "\n",
    "La forma m√°s simple de crear nodos de subgrafo es adjuntar un subgrafo directamente como un nodo. Al hacerlo, es importante que el grafo principal y el subgrafo compartan claves de estado, porque esas claves compartidas se usar√°n para comunicarse. (Si tu grafo y subgrafo no comparten ninguna clave, revisa la siguiente secci√≥n.)\n",
    "\n",
    "> **NOTA**  \n",
    "> Si pasas claves adicionales al nodo del subgrafo (es decir, adem√°s de las claves compartidas), ser√°n ignoradas por el nodo del subgrafo. De manera similar, si el subgrafo devuelve claves adicionales, ser√°n ignoradas por el grafo principal.\n",
    "\n",
    "Veamos c√≥mo se ve esto en acci√≥n:\n",
    "\n",
    "---\n",
    "\n",
    "#### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bcca982-a53a-4ba1-8b9f-c1fa22d7bde5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'foo': 'hellobar'}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: str  # esta clave se comparte con el subgrafo\n",
    "\n",
    "class SubgraphState(TypedDict):\n",
    "    foo: str  # esta clave se comparte con el grafo principal\n",
    "    bar: str\n",
    "\n",
    "# Definir subgrafo\n",
    "def subgraph_node(state: SubgraphState):\n",
    "    # Este subgrafo puede comunicarse con el grafo principal a trav√©s de la clave \"foo\"\n",
    "    return {\"foo\": state[\"foo\"] + \"bar\"}\n",
    "\n",
    "# Crear el builder del subgrafo\n",
    "subgraph_builder = StateGraph(SubgraphState)\n",
    "\n",
    "subgraph_builder.add_node(\"subgraph_node\", subgraph_node)\n",
    "\n",
    "# Conectar el nodo 'START' al nodo 'subgraph_node'\n",
    "subgraph_builder.add_edge(START, \"subgraph_node\")\n",
    "# Compila el subgrafo\n",
    "subgraph = subgraph_builder.compile()\n",
    "\n",
    "# Definir grafo principal\n",
    "builder = StateGraph(State)\n",
    "# Agrega el subgrafo como un nodo en el grafo principal\n",
    "builder.add_node(\"subgraph\", subgraph)\n",
    "# Conectar el nodo 'START' al nodo 'subgraph' en el grafo principal\n",
    "builder.add_edge(START, \"subgraph\")\n",
    "# Aqu√≠ puedes agregar m√°s nodos o configuraciones para el grafo principal si es necesario\n",
    "\n",
    "# Finalmente, compila el grafo principal\n",
    "graph = builder.compile()\n",
    "\n",
    "# Ahora, ejecutamos el grafo con un estado inicial\n",
    "state = {\"foo\": \"hello\"}\n",
    "result = graph.invoke(state)\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d41662a-82e1-4eb2-ab2d-ef24fb466bd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "### Llamar a un Subgrafo con una Funci√≥n\n",
    "\n",
    "Puede que quieras definir un subgrafo con un esquema completamente diferente. En ese caso, puedes crear un nodo con una **funci√≥n** que invoque al subgrafo. Esta funci√≥n necesitar√°:\n",
    "\n",
    "1. Transformar el estado del grafo principal al estado requerido por el subgrafo **antes** de invocarlo.\n",
    "2. Transformar los resultados del subgrafo **de regreso** al estado del grafo principal antes de devolver la actualizaci√≥n de estado desde el nodo.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86495305-dfc7-4e10-a6e0-0a7dcfa9e3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e204621-ec33-45d2-b034-106023b756c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'foo': 'hellobaz'}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "from typing import TypedDict\n",
    "\n",
    "# Estado del grafo principal\n",
    "class ParentState(TypedDict):\n",
    "    foo: str\n",
    "\n",
    "# Estado del subgrafo\n",
    "class SubgraphState(TypedDict):\n",
    "    bar: str\n",
    "\n",
    "# Subgrafo que trabaja sobre SubgraphState\n",
    "def subgraph_node(state: SubgraphState):\n",
    "    return {\"bar\": state[\"bar\"] + \"baz\"}\n",
    "\n",
    "subgraph_builder = StateGraph(SubgraphState)\n",
    "subgraph_builder.add_node(\"sub_node\", subgraph_node)\n",
    "subgraph_builder.add_edge(START, \"sub_node\")\n",
    "subgraph = subgraph_builder.compile()\n",
    "\n",
    "# Nodo del grafo principal que llama al subgrafo\n",
    "def subgraph_caller(state: ParentState):\n",
    "    # Transformar estado del grafo principal al del subgrafo\n",
    "    sub_state = {\"bar\": state[\"foo\"]}\n",
    "    # Ejecutar el subgrafo\n",
    "    result = subgraph.invoke(sub_state)\n",
    "    # Transformar resultado de regreso al estado del grafo principal\n",
    "    return {\"foo\": result[\"bar\"]}\n",
    "\n",
    "# Construcci√≥n del grafo principal\n",
    "parent_builder = StateGraph(ParentState)\n",
    "parent_builder.add_node(\"call_subgraph\", subgraph_caller)\n",
    "parent_builder.add_edge(START, \"call_subgraph\")\n",
    "graph = parent_builder.compile()\n",
    "\n",
    "# Probarlo\n",
    "result = graph.invoke({\"foo\": \"hello\"})\n",
    "print(result)  # {'foo': 'hellobaz'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55652d32-1edb-4ae5-bad8-f173e27bc91b",
   "metadata": {},
   "source": [
    "\n",
    "### Ahora que sabemos c√≥mo usar subgrafos, veamos uno de sus grandes casos de uso: **arquitecturas multiagente**.\n",
    "\n",
    "## Arquitecturas Multiagente\n",
    "\n",
    "A medida que los agentes basados en LLMs (modelos de lenguaje grandes) crecen en tama√±o, alcance o complejidad, pueden surgir varios problemas que afectan su rendimiento, como los siguientes:\n",
    "\n",
    "- El agente recibe demasiadas herramientas para elegir y toma malas decisiones sobre cu√°l usar a continuaci√≥n (el Cap√≠tulo 6 discuti√≥ algunos enfoques para este problema).\n",
    "- El contexto se vuelve demasiado complejo para que un solo agente lo mantenga bajo control; es decir, el tama√±o de los *prompts* y la cantidad de cosas mencionadas superan la capacidad del modelo que est√°s usando.\n",
    "- Quieres usar un subsistema especializado para una tarea en particular, por ejemplo: planeaci√≥n, investigaci√≥n, resoluci√≥n de problemas matem√°ticos, etc.\n",
    "\n",
    "Para abordar estos problemas, puedes considerar dividir tu aplicaci√≥n en m√∫ltiples agentes peque√±os e independientes, y componerlos en un sistema multiagente. Estos agentes pueden ser tan simples como un *prompt* con una llamada a un LLM o tan complejos como un agente tipo ReAct (introducido en el Cap√≠tulo 6). \n",
    "\n",
    "La **Figura 7-3** ilustra varias formas de conectar agentes en un sistema multiagente.\n",
    "\n",
    "---\n",
    "\n",
    "### Figura 7-3. M√∫ltiples estrategias para coordinar m√∫ltiples agentes\n",
    "\n",
    "Veamos con m√°s detalle la Figura 7-3:\n",
    "\n",
    "- **Red (Network)**  \n",
    "  Cada agente puede comunicarse con todos los dem√°s. Cualquier agente puede decidir cu√°l se ejecutar√° a continuaci√≥n.\n",
    "\n",
    "- **Supervisor**  \n",
    "  Cada agente se comunica con un √∫nico agente llamado *supervisor*. El supervisor toma decisiones sobre qu√© agente (o agentes) deben llamarse a continuaci√≥n. Un caso especial de esta arquitectura implementa el supervisor como una llamada a un LLM con herramientas (cubierto en el Cap√≠tulo 6).\n",
    "\n",
    "- **Jer√°rquica (Hierarchical)**  \n",
    "  Puedes definir un sistema multiagente con un supervisor de supervisores. Esta es una generalizaci√≥n de la arquitectura de supervisor y permite flujos de control m√°s complejos.\n",
    "\n",
    "- **Flujo personalizado (Custom multi-agent workflow)**  \n",
    "  Cada agente se comunica solo con un subconjunto de agentes. Partes del flujo son deterministas, y solo algunos agentes pueden decidir qu√© otros agentes llamar.\n",
    "\n",
    "---\n",
    "\n",
    "La siguiente secci√≥n profundiza en la arquitectura de tipo **supervisor**, que ofrece un buen equilibrio entre capacidad y facilidad de uso.\n",
    "\n",
    "---\n",
    "\n",
    "## Arquitectura de Supervisor\n",
    "\n",
    "En esta arquitectura, a√±adimos cada agente al grafo como un nodo y tambi√©n agregamos un nodo supervisor, que decide qu√© agentes deben llamarse a continuaci√≥n. Usamos **bordes condicionales** (*conditional edges*) para dirigir la ejecuci√≥n al nodo de agente apropiado con base en la decisi√≥n del supervisor. Puedes consultar el Cap√≠tulo 5 para una introducci√≥n a LangGraph, donde se abordan los conceptos de nodos, bordes y m√°s.\n",
    "\n",
    "---\n",
    "\n",
    "### Primero veamos c√≥mo se ve el nodo supervisor:\n",
    "\n",
    "**Python**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1224d405-66b3-475b-9c08-378f267faf53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class SupervisorDecision(BaseModel):\n",
    "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = model.with_structured_output(SupervisorDecision)\n",
    "\n",
    "agents = [\"researcher\", \"coder\"]\n",
    "\n",
    "system_prompt_part_1 = f\"\"\"You are a supervisor tasked with managing a \n",
    "conversation between the following workers: {agents}. Given the following user \n",
    "request, respond with the worker to act next. Each worker will perform a\n",
    "task and respond with their results and status. When finished,\n",
    "respond with FINISH.\"\"\"\n",
    "\n",
    "system_prompt_part_2 = f\"\"\"Given the conversation above, who should act next? Or \n",
    "    should we FINISH? Select one of: {', '.join(agents)}, FINISH\"\"\"\n",
    "\n",
    "def supervisor(state):\n",
    "    messages = [\n",
    "        (\"system\", system_prompt_part_1),\n",
    "        *state[\"messages\"],\n",
    "        (\"system\", \tsystem_prompt_part_2)\n",
    "    ]\n",
    "    return model.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd27b6e1-99e6-407c-be94-2fee5bd8fded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57f2e527-20de-494b-96f2-2cc042214242",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**NOTA**  \n",
    "El c√≥digo en el prompt requiere que los nombres de tus subagentes sean autoexplicativos y distintos. Por ejemplo, si simplemente se llamaran `agente_1` y `agente_2`, el modelo LLM no tendr√≠a informaci√≥n suficiente para decidir cu√°l es el adecuado para cada tarea. Si es necesario, puedes modificar el prompt para a√±adir una descripci√≥n de cada agente, lo cual podr√≠a ayudar al LLM a elegir un agente para cada consulta.\n",
    "\n",
    "Ahora veamos c√≥mo integrar este nodo supervisor en un grafo m√°s grande que incluya a otros dos subagentes, a los que llamaremos `investigador` (researcher) y `programador` (coder).  \n",
    "Nuestro objetivo general con este grafo es manejar consultas que puedan ser respondidas ya sea por el investigador, el programador, o incluso por ambos en sucesi√≥n.  \n",
    "\n",
    "Este ejemplo no incluye la implementaci√≥n del investigador o el programador‚Äîla idea clave es que podr√≠an ser cualquier otro nodo o subgrafo de LangGraph.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab643f76-41e4-4a77-a733-aa6c95bc5b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import MessagesState\n",
    "\n",
    "# Clase para que el supervisor decida\n",
    "class SupervisorDecision(BaseModel):\n",
    "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]\n",
    "\n",
    "# Modelo con salida estructurada\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = model.with_structured_output(SupervisorDecision)\n",
    "\n",
    "# Agentes disponibles\n",
    "agents = [\"researcher\", \"coder\"]\n",
    "\n",
    "# Prompts del supervisor\n",
    "system_prompt_part_1 = f\"\"\"You are a supervisor tasked with managing a \n",
    "conversation between the following workers: {agents}. Given the following user \n",
    "request, respond with the worker to act next. Each worker will perform a\n",
    "task and respond with their results and status. When finished,\n",
    "respond with FINISH.\"\"\"\n",
    "\n",
    "system_prompt_part_2 = f\"\"\"Given the conversation above, who should act next? Or \n",
    "should we FINISH? Select one of: {', '.join(agents)}, FINISH\"\"\"\n",
    "\n",
    "# Nodo supervisor\n",
    "def supervisor(state):\n",
    "    messages = [\n",
    "        (\"system\", system_prompt_part_1),\n",
    "        *state[\"messages\"],\n",
    "        (\"system\", system_prompt_part_2)\n",
    "    ]\n",
    "    result = model.invoke(messages)\n",
    "    return {\"next\": result.next}\n",
    "\n",
    "# Definimos el estado compartido entre agentes\n",
    "class AgentState(BaseModel):\n",
    "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]\n",
    "\n",
    "# Nodo para el agente 'researcher'\n",
    "def researcher(state: AgentState):\n",
    "    response = model.invoke(\"Haz una investigaci√≥n sobre el tema solicitado.\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Nodo para el agente 'coder'\n",
    "def coder(state: AgentState):\n",
    "    response = model.invoke(\"Escribe un fragmento de c√≥digo para la tarea dada.\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Construcci√≥n del grafo\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"supervisor\", supervisor)\n",
    "builder.add_node(\"researcher\", researcher)\n",
    "builder.add_node(\"coder\", coder)\n",
    "\n",
    "# Enlaces del grafo\n",
    "builder.set_entry_point(\"supervisor\")\n",
    "builder.add_conditional_edges(\"supervisor\", lambda state: state[\"next\"], {\n",
    "    \"researcher\": \"researcher\",\n",
    "    \"coder\": \"coder\",\n",
    "    \"FINISH\": END,\n",
    "})\n",
    "\n",
    "builder.add_edge(\"researcher\", \"supervisor\")\n",
    "builder.add_edge(\"coder\", \"supervisor\")\n",
    "\n",
    "# Compilar el grafo\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2553cc8-32a0-4eec-813f-ca4b33d39430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Literal, Annotated\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import MessagesState\n",
    "\n",
    "# 1. Modelo del supervisor con salida estructurada\n",
    "class SupervisorDecision(BaseModel):\n",
    "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]\n",
    "\n",
    "# 2. Agentes disponibles\n",
    "agents = [\"researcher\", \"coder\"]\n",
    "\n",
    "# 3. Instanciar modelos\n",
    "supervisor_model = ChatOpenAI(model=\"gpt-4o\", temperature=0).with_structured_output(SupervisorDecision)\n",
    "agent_model = ChatOpenAI(model=\"gpt-4o\", temperature=0.3)  # M√°s libre para responder creativamente\n",
    "\n",
    "\n",
    "# 4. Prompt del supervisor\n",
    "system_prompt_part_1 = f\"\"\"You are a supervisor tasked with managing a \n",
    "conversation between the following workers: {agents}. Given the following user \n",
    "request, respond with the worker to act next. Each worker will perform a\n",
    "task and respond with their results and status. When finished,\n",
    "respond with FINISH.\"\"\"\n",
    "\n",
    "system_prompt_part_2 = f\"\"\"\n",
    "Dada la conversaci√≥n anterior, decide qui√©n debe actuar a continuaci√≥n. Si el usuario ya ha recibido una respuesta completa y no hay m√°s acciones necesarias, responde √∫nicamente con: FINISH.\n",
    "\n",
    "Importante:\n",
    "- No reinicies el proceso si ya se respondi√≥ el tema central.\n",
    "- No repitas pasos innecesarios.\n",
    "- Elige solo una de las siguientes opciones: {', '.join(agents)}, FINISH.\n",
    "\"\"\"\n",
    "\n",
    "# 5. Nodo supervisor\n",
    "def supervisor(state: MessagesState):\n",
    "    messages = [\n",
    "        (\"system\", system_prompt_part_1),\n",
    "        *state[\"messages\"],\n",
    "        (\"system\", system_prompt_part_2)\n",
    "    ]\n",
    "    print(\":::::::::::::::::::::::::::::::::\", messages)\n",
    "    \n",
    "    print()\n",
    "    result = supervisor_model.invoke(messages)\n",
    "    \n",
    "    print(\"supervisor\", result.next)\n",
    "    return {\"next\": result.next}\n",
    "\n",
    "# 6. Nodo researcher\n",
    "def researcher(state: MessagesState):\n",
    "    messages =  state[\"messages\"][0].content  # solo tomamos el mensaje inicial\n",
    "    print(\"---------------------------\", messages)\n",
    "    print()\n",
    "\n",
    "    response = agent_model.invoke([HumanMessage(content=f\"Haz una investigaci√≥n sobre este tema : {messages}\")])\n",
    "    return {\"messages\": state[\"messages\"] +  [response]}\n",
    "\n",
    "# 7. Nodo coder\n",
    "def coder(state: MessagesState):\n",
    "    messages =  state[\"messages\"][0].content  # solo tomamos el mensaje inicial\n",
    "    response = agent_model.invoke([HumanMessage(content=f\"Escribe un fragmento de c√≥digo para este tema: {messages}\")])\n",
    "    return {\"messages\":  state[\"messages\"] +  [response]}\n",
    "# 8. Construcci√≥n del grafo\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"supervisor\", supervisor)\n",
    "builder.add_node(\"researcher\", researcher)\n",
    "builder.add_node(\"coder\", coder)\n",
    "\n",
    "builder.set_entry_point(\"supervisor\")\n",
    "\n",
    "builder.add_conditional_edges(\"supervisor\", lambda state: state[\"next\"], {\n",
    "    \"researcher\": \"researcher\",\n",
    "    \"coder\": \"coder\",\n",
    "    \"FINISH\": END,\n",
    "})\n",
    "\n",
    "builder.add_edge(\"researcher\", \"supervisor\")\n",
    "builder.add_edge(\"coder\", \"supervisor\")\n",
    "\n",
    "# 9. Compilar el grafo\n",
    "graph = builder.compile()\n",
    "\n",
    "# 10. Funci√≥n para correr el grafo\n",
    "def run_graph_with_prompt(user_prompt: str):\n",
    "    input_state = {\"messages\": [HumanMessage(content=user_prompt)]}\n",
    "\n",
    "    for step_name in graph.stream(input_state):\n",
    "        print(f\"\\n>>> Paso: {step_name}\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c0226a8-c1f6-4777-9279-eef5cc1497e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::::::::::::::::::::::::::::::::: [('system', \"You are a supervisor tasked with managing a \\nconversation between the following workers: ['researcher', 'coder']. Given the following user \\nrequest, respond with the worker to act next. Each worker will perform a\\ntask and respond with their results and status. When finished,\\nrespond with FINISH.\"), HumanMessage(content='Necesito ayuda para una investigaci√≥n sobre el cambio clim√°tico.', additional_kwargs={}, response_metadata={}, id='fd7b0013-b11e-4d66-9a45-43b7e482f7af'), ('system', '\\nDada la conversaci√≥n anterior, decide qui√©n debe actuar a continuaci√≥n. Si el usuario ya ha recibido una respuesta completa y no hay m√°s acciones necesarias, responde √∫nicamente con: FINISH.\\n\\nImportante:\\n- No reinicies el proceso si ya se respondi√≥ el tema central.\\n- No repitas pasos innecesarios.\\n- Elige solo una de las siguientes opciones: researcher, coder, FINISH.\\n')]\n",
      "\n",
      "supervisor researcher\n",
      "\n",
      ">>> Paso: {'supervisor': None}\n",
      "--------------------------- Necesito ayuda para una investigaci√≥n sobre el cambio clim√°tico.\n",
      "\n",
      "\n",
      ">>> Paso: {'researcher': {'messages': [HumanMessage(content='Necesito ayuda para una investigaci√≥n sobre el cambio clim√°tico.', additional_kwargs={}, response_metadata={}, id='fd7b0013-b11e-4d66-9a45-43b7e482f7af'), AIMessage(content='El cambio clim√°tico es uno de los desaf√≠os m√°s importantes y urgentes que enfrenta la humanidad en el siglo XXI. A continuaci√≥n, te proporciono una gu√≠a b√°sica sobre los aspectos clave que podr√≠as investigar para desarrollar un trabajo completo sobre este tema:\\n\\n### 1. **Definici√≥n y Causas del Cambio Clim√°tico**\\n   - **Definici√≥n:** El cambio clim√°tico se refiere a las variaciones a largo plazo en las temperaturas y los patrones clim√°ticos de la Tierra. Aunque estos cambios pueden ser naturales, desde el siglo XIX, las actividades humanas han sido el principal impulsor del cambio clim√°tico, principalmente debido a la quema de combustibles f√≥siles como el carb√≥n, el petr√≥leo y el gas.\\n   - **Causas Principales:**\\n     - **Gases de Efecto Invernadero (GEI):** El di√≥xido de carbono (CO2), el metano (CH4) y el √≥xido nitroso (N2O) son los principales GEI que contribuyen al calentamiento global.\\n     - **Deforestaci√≥n:** La tala de bosques reduce la capacidad de la Tierra para absorber CO2.\\n     - **Agricultura y Ganader√≠a:** Estas actividades emiten metano y otros GEI.\\n\\n### 2. **Impactos del Cambio Clim√°tico**\\n   - **Ecosistemas y Biodiversidad:** Cambios en los h√°bitats, extinci√≥n de especies, y alteraci√≥n de los ciclos naturales.\\n   - **Fen√≥menos Meteorol√≥gicos Extremos:** Aumento en la frecuencia e intensidad de huracanes, sequ√≠as, inundaciones y olas de calor.\\n   - **Nivel del Mar:** El derretimiento de los glaciares y el hielo polar contribuye al aumento del nivel del mar, amenazando a las comunidades costeras.\\n   - **Salud Humana:** Aumento de enfermedades relacionadas con el calor, problemas respiratorios por la contaminaci√≥n del aire, y propagaci√≥n de enfermedades transmitidas por vectores.\\n\\n### 3. **Mitigaci√≥n y Adaptaci√≥n**\\n   - **Mitigaci√≥n:** Acciones para reducir o prevenir la emisi√≥n de GEI. Esto incluye el uso de energ√≠as renovables, eficiencia energ√©tica, y reforestaci√≥n.\\n   - **Adaptaci√≥n:** Ajustes en sistemas humanos o naturales en respuesta a los efectos del cambio clim√°tico. Ejemplos incluyen la construcci√≥n de infraestructuras resistentes al clima y el desarrollo de cultivos resistentes a la sequ√≠a.\\n\\n### 4. **Pol√≠ticas y Acuerdos Internacionales**\\n   - **Protocolo de Kioto:** Un acuerdo internacional que establece compromisos vinculantes para reducir las emisiones de GEI.\\n   - **Acuerdo de Par√≠s:** Un pacto global para limitar el calentamiento global a menos de 2 grados Celsius por encima de los niveles preindustriales, con esfuerzos para limitarlo a 1.5 grados.\\n\\n### 5. **Rol de la Ciencia y la Tecnolog√≠a**\\n   - **Investigaci√≥n Cient√≠fica:** Modelos clim√°ticos, estudios de impacto, y monitoreo de cambios ambientales.\\n   - **Innovaci√≥n Tecnol√≥gica:** Desarrollo de tecnolog√≠as limpias, captura y almacenamiento de carbono, y geoingenier√≠a.\\n\\n### 6. **Participaci√≥n Ciudadana y Educaci√≥n**\\n   - **Conciencia P√∫blica:** Educaci√≥n sobre el cambio clim√°tico y sus impactos.\\n   - **Acciones Comunitarias:** Iniciativas locales para reducir la huella de carbono y promover la sostenibilidad.\\n\\n### 7. **Desaf√≠os y Oportunidades**\\n   - **Desaf√≠os:** Resistencia pol√≠tica, desigualdad en la responsabilidad y los impactos, y la necesidad de una transici√≥n justa.\\n   - **Oportunidades:** Desarrollo de econom√≠as verdes, creaci√≥n de empleos sostenibles, y mejora de la calidad de vida.\\n\\nPara una investigaci√≥n m√°s detallada, podr√≠as centrarte en un aspecto espec√≠fico del cambio clim√°tico, como el impacto en una regi√≥n particular, el papel de una industria espec√≠fica en las emisiones de GEI, o las pol√≠ticas de un pa√≠s en particular. Adem√°s, es importante consultar fuentes acad√©micas, informes de organizaciones internacionales como el IPCC (Panel Intergubernamental sobre Cambio Clim√°tico), y datos de agencias meteorol√≥gicas y ambientales.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 860, 'prompt_tokens': 25, 'total_tokens': 885, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BOg7Tn7fcNwQ0gsWs11UZcL7tuNY2', 'finish_reason': 'stop', 'logprobs': None}, id='run-e0e68ddc-da96-48ed-b80c-347b63ef75e6-0', usage_metadata={'input_tokens': 25, 'output_tokens': 860, 'total_tokens': 885, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "::::::::::::::::::::::::::::::::: [('system', \"You are a supervisor tasked with managing a \\nconversation between the following workers: ['researcher', 'coder']. Given the following user \\nrequest, respond with the worker to act next. Each worker will perform a\\ntask and respond with their results and status. When finished,\\nrespond with FINISH.\"), HumanMessage(content='Necesito ayuda para una investigaci√≥n sobre el cambio clim√°tico.', additional_kwargs={}, response_metadata={}, id='fd7b0013-b11e-4d66-9a45-43b7e482f7af'), AIMessage(content='El cambio clim√°tico es uno de los desaf√≠os m√°s importantes y urgentes que enfrenta la humanidad en el siglo XXI. A continuaci√≥n, te proporciono una gu√≠a b√°sica sobre los aspectos clave que podr√≠as investigar para desarrollar un trabajo completo sobre este tema:\\n\\n### 1. **Definici√≥n y Causas del Cambio Clim√°tico**\\n   - **Definici√≥n:** El cambio clim√°tico se refiere a las variaciones a largo plazo en las temperaturas y los patrones clim√°ticos de la Tierra. Aunque estos cambios pueden ser naturales, desde el siglo XIX, las actividades humanas han sido el principal impulsor del cambio clim√°tico, principalmente debido a la quema de combustibles f√≥siles como el carb√≥n, el petr√≥leo y el gas.\\n   - **Causas Principales:**\\n     - **Gases de Efecto Invernadero (GEI):** El di√≥xido de carbono (CO2), el metano (CH4) y el √≥xido nitroso (N2O) son los principales GEI que contribuyen al calentamiento global.\\n     - **Deforestaci√≥n:** La tala de bosques reduce la capacidad de la Tierra para absorber CO2.\\n     - **Agricultura y Ganader√≠a:** Estas actividades emiten metano y otros GEI.\\n\\n### 2. **Impactos del Cambio Clim√°tico**\\n   - **Ecosistemas y Biodiversidad:** Cambios en los h√°bitats, extinci√≥n de especies, y alteraci√≥n de los ciclos naturales.\\n   - **Fen√≥menos Meteorol√≥gicos Extremos:** Aumento en la frecuencia e intensidad de huracanes, sequ√≠as, inundaciones y olas de calor.\\n   - **Nivel del Mar:** El derretimiento de los glaciares y el hielo polar contribuye al aumento del nivel del mar, amenazando a las comunidades costeras.\\n   - **Salud Humana:** Aumento de enfermedades relacionadas con el calor, problemas respiratorios por la contaminaci√≥n del aire, y propagaci√≥n de enfermedades transmitidas por vectores.\\n\\n### 3. **Mitigaci√≥n y Adaptaci√≥n**\\n   - **Mitigaci√≥n:** Acciones para reducir o prevenir la emisi√≥n de GEI. Esto incluye el uso de energ√≠as renovables, eficiencia energ√©tica, y reforestaci√≥n.\\n   - **Adaptaci√≥n:** Ajustes en sistemas humanos o naturales en respuesta a los efectos del cambio clim√°tico. Ejemplos incluyen la construcci√≥n de infraestructuras resistentes al clima y el desarrollo de cultivos resistentes a la sequ√≠a.\\n\\n### 4. **Pol√≠ticas y Acuerdos Internacionales**\\n   - **Protocolo de Kioto:** Un acuerdo internacional que establece compromisos vinculantes para reducir las emisiones de GEI.\\n   - **Acuerdo de Par√≠s:** Un pacto global para limitar el calentamiento global a menos de 2 grados Celsius por encima de los niveles preindustriales, con esfuerzos para limitarlo a 1.5 grados.\\n\\n### 5. **Rol de la Ciencia y la Tecnolog√≠a**\\n   - **Investigaci√≥n Cient√≠fica:** Modelos clim√°ticos, estudios de impacto, y monitoreo de cambios ambientales.\\n   - **Innovaci√≥n Tecnol√≥gica:** Desarrollo de tecnolog√≠as limpias, captura y almacenamiento de carbono, y geoingenier√≠a.\\n\\n### 6. **Participaci√≥n Ciudadana y Educaci√≥n**\\n   - **Conciencia P√∫blica:** Educaci√≥n sobre el cambio clim√°tico y sus impactos.\\n   - **Acciones Comunitarias:** Iniciativas locales para reducir la huella de carbono y promover la sostenibilidad.\\n\\n### 7. **Desaf√≠os y Oportunidades**\\n   - **Desaf√≠os:** Resistencia pol√≠tica, desigualdad en la responsabilidad y los impactos, y la necesidad de una transici√≥n justa.\\n   - **Oportunidades:** Desarrollo de econom√≠as verdes, creaci√≥n de empleos sostenibles, y mejora de la calidad de vida.\\n\\nPara una investigaci√≥n m√°s detallada, podr√≠as centrarte en un aspecto espec√≠fico del cambio clim√°tico, como el impacto en una regi√≥n particular, el papel de una industria espec√≠fica en las emisiones de GEI, o las pol√≠ticas de un pa√≠s en particular. Adem√°s, es importante consultar fuentes acad√©micas, informes de organizaciones internacionales como el IPCC (Panel Intergubernamental sobre Cambio Clim√°tico), y datos de agencias meteorol√≥gicas y ambientales.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 860, 'prompt_tokens': 25, 'total_tokens': 885, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BOg7Tn7fcNwQ0gsWs11UZcL7tuNY2', 'finish_reason': 'stop', 'logprobs': None}, id='run-e0e68ddc-da96-48ed-b80c-347b63ef75e6-0', usage_metadata={'input_tokens': 25, 'output_tokens': 860, 'total_tokens': 885, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ('system', '\\nDada la conversaci√≥n anterior, decide qui√©n debe actuar a continuaci√≥n. Si el usuario ya ha recibido una respuesta completa y no hay m√°s acciones necesarias, responde √∫nicamente con: FINISH.\\n\\nImportante:\\n- No reinicies el proceso si ya se respondi√≥ el tema central.\\n- No repitas pasos innecesarios.\\n- Elige solo una de las siguientes opciones: researcher, coder, FINISH.\\n')]\n",
      "\n",
      "supervisor researcher\n",
      "\n",
      ">>> Paso: {'supervisor': None}\n",
      "--------------------------- Necesito ayuda para una investigaci√≥n sobre el cambio clim√°tico.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_118/479827556.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_graph_with_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Necesito ayuda para una investigaci√≥n sobre el cambio clim√°tico.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_118/1165636977.py\u001b[0m in \u001b[0;36mrun_graph_with_prompt\u001b[0;34m(user_prompt)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0minput_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n>>> Paso: {step_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2375\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2376\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2377\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2378\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2379\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    159\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_118/1165636977.py\u001b[0m in \u001b[0;36mresearcher\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Haz una investigaci√≥n sobre este tema : {messages}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m         return cast(\n\u001b[1;32m    367\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    369\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    936\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m                 results.append(\n\u001b[0;32m--> 759\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    760\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1003\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             )\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    989\u001b[0m             \u001b[0mgeneration_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    927\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    928\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             body=maybe_transform(\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m         )\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     def patch(\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    950\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m    990\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    231\u001b[0m         )\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    197\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     )\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    114\u001b[0m                 trace.return_value = (\n\u001b[1;32m    115\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    225\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 )\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1258\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1260\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1133\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_graph_with_prompt(\"Necesito ayuda para una investigaci√≥n sobre el cambio clim√°tico.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ed346e-3024-4195-ae92-7c7ec6ed8a4b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Algunas cosas a notar:\n",
    "\n",
    "En este ejemplo, ambos subagentes (**researcher** y **coder**) pueden ver el trabajo del otro, ya que todo el progreso se guarda en la lista de `messages`. Pero **no es la √∫nica forma** de organizar esto. Cada uno de los subagentes podr√≠a ser m√°s complejo. Por ejemplo, un subagente podr√≠a ser su propio grafo que mantenga un estado interno y solo saque un resumen de lo que hizo.\n",
    "\n",
    "Despu√©s de que cada agente act√∫e, volvemos al nodo **supervisor**, que decide si queda algo por hacer y a cu√°l agente deleg√°rselo. Pero este enrutamiento **no es obligatorio** en esta arquitectura. Tambi√©n podr√≠as hacer que cada subagente decida si su salida se regresa directamente al usuario. Para eso, tendr√≠as que reemplazar la conexi√≥n directa entre, por ejemplo, `researcher` y `supervisor`, por una conexi√≥n condicional (que lea una clave del estado actualizada por `researcher`).\n",
    "\n",
    "---\n",
    "\n",
    "### Resumen:\n",
    "\n",
    "Este cap√≠tulo cubre dos extensiones importantes para la arquitectura de agentes:\n",
    "- **Reflexi√≥n**\n",
    "- **Arquitecturas multiagente**\n",
    "\n",
    "Tambi√©n vimos c√≥mo trabajar con **subgrafos** en LangGraph, que son un componente clave en estos sistemas multiagente.\n",
    "\n",
    "Estas extensiones le dan m√°s poder a la arquitectura basada en agentes con LLM, pero **no deber√≠an ser lo primero que uses** cuando crees un agente nuevo. Lo mejor es empezar con la arquitectura directa explicada en el **Cap√≠tulo 6**.\n",
    "\n",
    "---\n",
    "\n",
    "### Lo que viene (Cap√≠tulo 8):\n",
    "\n",
    "Regresamos al dilema entre **confiabilidad** y **agencia**, que es una decisi√≥n cr√≠tica al construir apps con LLM hoy en d√≠a. Esto se vuelve a√∫n m√°s importante cuando usas arquitecturas de agentes o multiagentes, ya que su poder puede traer caos si no lo controlas. En el cap√≠tulo siguiente se explican t√©cnicas clave para manejar esta decisi√≥n y **mejorar tus agentes y aplicaciones**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84529fc0-5d29-42ef-bc52-80488dd4b512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
