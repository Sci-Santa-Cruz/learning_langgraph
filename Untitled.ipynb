{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60af7171-c7b9-45a6-b030-2166177cff3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = key  # reemplaza con tu clave real si es necesario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe10f3ef-0321-4ec6-9b3e-7c4d77ccfee0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: langchain-community 0.3.21\n",
      "Uninstalling langchain-community-0.3.21:\n",
      "  Successfully uninstalled langchain-community-0.3.21\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall -y langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "210dea32-54f6-40ef-b8a2-c5266cfaf923",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.75.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: Apache-2.0\n",
      "Location: /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages\n",
      "Requires: sniffio, tqdm, httpx, pydantic, anyio, jiter, distro, typing-extensions\n",
      "Required-by: langchain-openai\n",
      "---\n",
      "Name: langchain\n",
      "Version: 0.3.23\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages\n",
      "Requires: SQLAlchemy, langchain-core, async-timeout, PyYAML, langsmith, requests, pydantic, langchain-text-splitters\n",
      "Required-by: \n",
      "---\n",
      "Name: langgraph\n",
      "Version: 0.3.31\n",
      "Summary: Building stateful, multi-actor applications with LLMs\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages\n",
      "Requires: langgraph-checkpoint, xxhash, langgraph-prebuilt, langgraph-sdk, langchain-core\n",
      "Required-by: \n",
      "---\n",
      "Name: langchain-openai\n",
      "Version: 0.3.14\n",
      "Summary: An integration package connecting OpenAI and LangChain\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages\n",
      "Requires: openai, tiktoken, langchain-core\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show openai langchain langgraph langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee16ecf-89d8-4dbf-8f1f-5a7c051d6e38",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 📘 **Capítulo 7. Agentes II**\n",
    "\n",
    "El Capítulo 6 presentó la arquitectura de agentes, la más poderosa de las arquitecturas de LLM que hemos visto hasta ahora. Es difícil exagerar el potencial de esta combinación de encadenamiento de pensamientos, uso de herramientas y bucles.\n",
    "\n",
    "Este capítulo analiza dos extensiones de la arquitectura de agentes que mejoran el rendimiento para algunos casos de uso:\n",
    "\n",
    "---\n",
    "\n",
    "#### **Reflexión**\n",
    "\n",
    "Tomando otra página del repertorio de patrones de pensamiento humano, esto trata sobre darle a tu aplicación con LLM la oportunidad de analizar sus propias salidas y elecciones pasadas, junto con la capacidad de recordar reflexiones de iteraciones anteriores.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Multi-agente**\n",
    "\n",
    "De manera similar a cómo un equipo puede lograr más que una sola persona, hay problemas que pueden abordarse mejor con equipos de agentes LLM.\n",
    "\n",
    "---\n",
    "\n",
    "Comencemos con la reflexión.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Reflexión**\n",
    "\n",
    "Una técnica de prompts que aún no hemos cubierto es la reflexión (también conocida como autocrítica). La reflexión es la creación de un bucle entre un prompt generador y un prompt revisor. Esto refleja el proceso de creación de muchos artefactos generados por humanos, como este capítulo que estás leyendo ahora, el cual es el resultado de un ida y vuelta entre los autores, revisores y editor, hasta que todos estén satisfechos con el producto final.\n",
    "\n",
    "Como muchas de las técnicas de prompts que hemos visto hasta ahora, la reflexión se puede combinar con otras técnicas, como el encadenamiento de pensamientos (chain-of-thought) y el uso de herramientas. En esta sección, veremos la reflexión de forma aislada.\n",
    "\n",
    "Se puede trazar un paralelo con los modos de pensamiento humano conocidos como Sistema 1 (reactivo o instintivo) y Sistema 2 (metódico y reflexivo), introducidos por primera vez por Daniel Kahneman en su libro *Thinking, Fast and Slow* (Farrar, Straus and Giroux, 2011). Cuando se aplica correctamente, la autocrítica puede ayudar a que las aplicaciones con LLM se acerquen a algo que se asemeje al comportamiento del Sistema 2 (Figura 7-1).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Figura 7-1. Pensamiento del Sistema 1 y del Sistema 2**\n",
    "\n",
    "Implementaremos la reflexión como un grafo con dos nodos: **generar** y **reflexionar**. Este grafo tendrá la tarea de escribir ensayos de tres párrafos, con el nodo `generate` escribiendo o revisando borradores del ensayo, y `reflect` escribiendo una crítica para informar la siguiente revisión. Ejecutaremos el bucle un número fijo de veces, pero una variación de esta técnica sería permitir que el nodo de reflexión decida cuándo terminar. Veamos cómo se ve:\n",
    "\n",
    "---\n",
    "\n",
    "### 🐍 Código Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f839b0d-7dbd-42fd-970d-61495eb8cf02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c555a4-dfea-4b0b-8414-2e8bbf5eca5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# Definimos el estado del grafo, que es una lista de mensajes\n",
    "class Estado(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "# Prompt para generar ensayos\n",
    "prompt_generar = SystemMessage(\n",
    "    \"\"\"Eres un asistente de ensayos encargado de escribir excelentes ensayos \n",
    "    de 3 párrafos.\"\"\"\n",
    "    \"Genera el mejor ensayo posible para la solicitud del usuario.\"\n",
    "    \"\"\"Si el usuario proporciona una crítica, responde con una versión \n",
    "    revisada de tus intentos anteriores.\"\"\"\n",
    ")\n",
    "\n",
    "# Nodo de generación\n",
    "def generar(estado: Estado) -> Estado:\n",
    "    respuesta = model.invoke([prompt_generar] + estado[\"messages\"])\n",
    "    return {\"messages\": [respuesta]}\n",
    "\n",
    "# Prompt para reflexionar (criticar el ensayo)\n",
    "prompt_reflexion = SystemMessage(\n",
    "    \"\"\"Eres un profesor que califica un ensayo. Genera críticas y \n",
    "    recomendaciones para la entrega del usuario.\"\"\"\n",
    "    \"\"\"Proporciona recomendaciones detalladas, incluyendo solicitudes sobre \n",
    "    longitud, profundidad, estilo, etc.\"\"\"\n",
    ")\n",
    "\n",
    "# Nodo de reflexión\n",
    "def reflexionar(estado: Estado) -> Estado:\n",
    "    # Invertimos los mensajes para que el LLM reflexione sobre su propia salida\n",
    "    cls_map = {AIMessage: HumanMessage, HumanMessage: AIMessage}\n",
    "    # Primer mensaje es la solicitud original del usuario; se mantiene igual\n",
    "    traducido = [prompt_reflexion, estado[\"messages\"][0]] + [\n",
    "        cls_map[msg.__class__](content=msg.content) \n",
    "        for msg in estado[\"messages\"][1:]\n",
    "    ]\n",
    "    respuesta = model.invoke(traducido)\n",
    "    # Tratamos la salida como retroalimentación humana para el generador\n",
    "    return {\"messages\": [HumanMessage(content=respuesta.content)]}\n",
    "\n",
    "# Condición para detener el bucle\n",
    "def deberia_continuar(estado: Estado):\n",
    "    if len(estado[\"messages\"]) > 6:\n",
    "        # Terminamos después de 3 iteraciones, cada una con 2 mensajes\n",
    "        return END\n",
    "    else:\n",
    "        return \"reflect\"\n",
    "\n",
    "# Construcción del grafo\n",
    "construccion = StateGraph(Estado)\n",
    "construccion.add_node(\"generate\", generar)\n",
    "construccion.add_node(\"reflect\", reflexionar)\n",
    "construccion.add_edge(START, \"generate\")\n",
    "construccion.add_conditional_edges(\"generate\", deberia_continuar)\n",
    "construccion.add_edge(\"reflect\", \"generate\")\n",
    "\n",
    "# Compilar el grafo\n",
    "grafo = construccion.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ccb963-503b-45d7-9725-0a496e93b8fd",
   "metadata": {},
   "source": [
    "Este bloque de código define el **nodo de reflexión** dentro de un flujo donde un LLM escribe y luego se revisa a sí mismo. Vamos línea por línea:\n",
    "\n",
    "---\n",
    "\n",
    "### `def reflexionar(estado: Estado) -> Estado:`\n",
    "Define una función llamada `reflexionar` que recibe un diccionario con estado (`Estado`), y devuelve otro estado.\n",
    "\n",
    "---\n",
    "\n",
    "### `cls_map = {AIMessage: HumanMessage, HumanMessage: AIMessage}`\n",
    "Esta línea define un **mapa de clases inversas**. Su propósito es **intercambiar los roles** de los mensajes:\n",
    "- Lo que fue generado por el LLM (`AIMessage`), ahora será tratado como si lo hubiera dicho un humano (`HumanMessage`).\n",
    "- Y viceversa (aunque en este caso, eso no se usa).\n",
    "\n",
    "Este \"truco\" hace que el modelo analice su propia respuesta como si **otro humano lo hubiera dicho**, promoviendo una reflexión más efectiva.\n",
    "\n",
    "---\n",
    "\n",
    "### `traducido = [prompt_reflexion, estado[\"messages\"][0]] + [ ... ]`\n",
    "Aquí se está construyendo una nueva lista de mensajes:\n",
    "1. Primero, se añade el mensaje del sistema `prompt_reflexion`, que le dice al modelo que actúe como maestro que evalúa un ensayo.\n",
    "2. Luego se agrega el **mensaje original del usuario**, sin cambios (índice 0).\n",
    "3. Después, **todos los mensajes posteriores** (respuestas del LLM, principalmente) se transforman a su clase contraria, usando `cls_map`.\n",
    "\n",
    "Esto es como decirle al modelo:  \n",
    "*\"Aquí está la conversación, pero trata lo que tú dijiste como si lo hubiera dicho otra persona y ahora evalúalo.\"*\n",
    "\n",
    "---\n",
    "\n",
    "### `respuesta = model.invoke(traducido)`\n",
    "Aquí se invoca al modelo con esa conversación transformada, para que genere su **crítica o retroalimentación**.\n",
    "\n",
    "---\n",
    "\n",
    "### `return {\"messages\": [HumanMessage(content=respuesta.content)]}`\n",
    "Finalmente, se encapsula la crítica como si fuera un mensaje **humano** (simulando que viene de un revisor), y se devuelve como nuevo estado. Esto lo usará el generador para mejorar su ensayo en la siguiente iteración.\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Para qué sirve todo esto?\n",
    "Este nodo permite que el modelo **aprenda de sí mismo en cada iteración**, generando mejores resultados conforme reflexiona y revisa sus respuestas anteriores. Es como un ciclo de borradores y correcciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35100f04-56e5-4cdb-bf79-1d0f3ee7f617",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Resultado final:\n",
      "\n",
      "🙋 Humano:\n",
      "Escribe un ensayo sobre el impacto de la inteligencia artificial en la educación\n",
      "\n",
      "🤖 AI:\n",
      "La inteligencia artificial (IA) ha revolucionado numerosos aspectos de nuestras vidas, y la educación no es una excepción. El impacto de la IA en la educación es profundo y prometedor. En primer lugar, la IA ha permitido la personalización del aprendizaje, adaptando el contenido educativo a las necesidades individuales de cada estudiante. A través de algoritmos inteligentes, se pueden crear programas educativos individualizados que maximizan el potencial de cada alumno, permitiéndoles avanzar a su propio ritmo y en áreas donde más lo necesitan.\n",
      "\n",
      "En segundo lugar, la IA ha facilitado la accesibilidad a la educación, rompiendo barreras geográficas y económicas. Plataformas educativas basadas en IA ofrecen cursos en línea gratuitos o a precios accesibles, permitiendo que personas de todo el mundo puedan acceder a una educación de calidad. Además, la IA ha contribuido al desarrollo de tecnologías como los asistentes virtuales y los chatbots educativos, que brindan apoyo constante a los estudiantes fuera del aula y los guían en su proceso de aprendizaje.\n",
      "\n",
      "Por último, aunque la IA presenta grandes beneficios en la educación, también plantea desafíos éticos y sociales. Es fundamental garantizar la transparencia en el uso de la IA en el ámbito educativo, así como fomentar la educación digital y la alfabetización tecnológica para que los estudiantes puedan comprender y cuestionar el papel de la IA en su aprendizaje. En resumen, la inteligencia artificial está transformando la educación, ofreciendo nuevas oportunidades y desafíos que debemos abordar de manera responsable y equitativa.\n",
      "\n",
      "🙋 Humano:\n",
      "Tu ensayo ofrece una visión general interesante sobre el impacto de la inteligencia artificial en la educación. Aquí tienes algunas críticas y recomendaciones para mejorar tu entrega:\n",
      "\n",
      "1. **Extensión del ensayo**: Aunque tu ensayo aborda el tema de manera concisa, sería beneficioso profundizar más en cada punto que mencionas. Considera expandir tus ideas con ejemplos concretos, datos estadísticos o estudios de caso para respaldar tus argumentos y hacer que tu ensayo sea más persuasivo.\n",
      "\n",
      "2. **Coherencia y fluidez**: Asegúrate de estructurar tu ensayo de manera lógica para que los lectores puedan seguir fácilmente tu argumento. Utiliza conectores y palabras de transición para que tu ensayo fluya de manera coherente de una idea a otra.\n",
      "\n",
      "3. **Perspectiva crítica**: Aunque mencionas brevemente los desafíos éticos y sociales que plantea la IA en la educación, sería útil profundizar en estos aspectos. Explora más a fondo cómo la IA puede afectar la privacidad de los estudiantes, la equidad en el acceso a la educación y la pérdida de empleos en el sector educativo debido a la automatización.\n",
      "\n",
      "4. **Conclusión sólida**: Tu conclusión es un buen resumen de tus puntos principales, pero podría ser más contundente. Podrías incluir una reflexión final que resuma tus argumentos clave y plantee preguntas que inviten a la reflexión sobre el futuro de la educación con la IA.\n",
      "\n",
      "5. **Estilo de escritura**: Intenta mantener un tono académico en tu ensayo y evita el lenguaje informal. Además, asegúrate de revisar la redacción y la gramática para mejorar la claridad y la cohesión de tu texto.\n",
      "\n",
      "En general, tu ensayo tiene una base sólida, pero hay áreas donde puedes expandir y mejorar tu análisis para hacerlo más completo y persuasivo. Sigue trabajando en el desarrollo de tus ideas y en la organización de tu ensayo para construir un argumento más sólido y convincente. ¡Buena suerte!\n",
      "\n",
      "🤖 AI:\n",
      "La inteligencia artificial (IA) está dejando una huella indeleble en el campo de la educación, transformando significativamente la forma en que aprendemos y enseñamos. Uno de los impactos más notables de la IA en la educación es la personalización del aprendizaje. A través de algoritmos inteligentes, se pueden crear programas educativos adaptados a las necesidades individuales de cada estudiante, permitiéndoles avanzar a su propio ritmo y profundizar en áreas específicas de interés. Por ejemplo, plataformas como Khan Academy utilizan la IA para recomendar contenido educativo personalizado con el objetivo de maximizar el potencial de cada alumno.\n",
      "\n",
      "Además, la IA ha facilitado la accesibilidad a la educación al romper barreras geográficas y económicas. Plataformas en línea como Coursera o edX ofrecen una amplia gama de cursos gratuitos o a precios accesibles, permitiendo que personas de todo el mundo puedan acceder a una educación de calidad desde la comodidad de sus hogares. Asimismo, la IA ha dado lugar a tecnologías innovadoras como los asistentes virtuales y los chatbots educativos, que brindan apoyo personalizado a los estudiantes fuera del aula y los guían en su proceso de aprendizaje de manera interactiva y eficaz.\n",
      "\n",
      "No obstante, a pesar de los beneficios evidentes de la IA en la educación, también plantea desafíos éticos y sociales que no podemos pasar por alto. Es fundamental abordar la cuestión de la transparencia en el uso de la IA en el ámbito educativo, así como garantizar la equidad en el acceso y la privacidad de los datos de los estudiantes. Además, la automatización generada por la IA podría tener repercusiones en el empleo en el sector educativo, lo que requiere una reflexión crítica sobre cómo preparar a los educadores para los cambios tecnológicos en curso. En conclusión, la inteligencia artificial ha revolucionado la educación, ofreciendo nuevas posibilidades y desafíos que deben ser abordados de manera equitativa y responsable para garantizar un futuro educativo inclusivo y sostenible.\n",
      "\n",
      "🙋 Humano:\n",
      "¡Excelente trabajo en tu ensayo! Has abordado de manera clara y concisa el impacto de la inteligencia artificial en la educación, destacando tanto los beneficios como los desafíos que presenta esta tecnología. Aquí tienes algunas recomendaciones para mejorar tu entrega:\n",
      "\n",
      "1. **Profundidad en los ejemplos y evidencia**: Aunque mencionas ejemplos relevantes, como Khan Academy y Coursera, podrías profundizar un poco más en cómo específicamente utilizan la IA para personalizar el aprendizaje y mejorar la accesibilidad educativa. Agregar ejemplos concretos y datos estadísticos fortalecerá tus argumentos y brindará mayor credibilidad a tu ensayo.\n",
      "\n",
      "2. **Análisis crítico**: Aunque tocas brevemente los desafíos éticos y sociales de la IA en la educación, podrías expandir esta sección. Profundiza en cómo la falta de transparencia podría afectar a los estudiantes y educadores, y cómo se podrían abordar las preocupaciones relacionadas con la privacidad de los datos en entornos educativos impulsados por la IA.\n",
      "\n",
      "3. **Perspectiva del futuro**: Sería beneficioso incluir una sección que explore posibles escenarios futuros en el ámbito educativo con la creciente influencia de la IA. ¿Cómo crees que la IA continuará transformando la educación en los próximos años? La especulación informada podría enriquecer tu análisis y agregar un componente de anticipación.\n",
      "\n",
      "4. **Conexiones más sólidas entre los párrafos**: Asegúrate de que haya una transición suave entre tus ideas y párrafos para que tu ensayo fluya de manera coherente y lógica. Utiliza conectores y frases de transición para guiar al lector a lo largo de tu argumento de manera clara.\n",
      "\n",
      "En general, tu ensayo es sólido y bien estructurado. Continúa profundizando en tus argumentos, respaldándolos con ejemplos concretos y evidencia sólida para hacer que tu ensayo sea aún más convincente y completo. ¡Sigue así!\n",
      "\n",
      "🤖 AI:\n",
      "La inteligencia artificial (IA) está transformando el panorama educativo de manera significativa, ofreciendo beneficios sustanciales pero también planteando desafíos importantes que deben abordarse con responsabilidad. La personalización del aprendizaje es uno de los puntos más destacados del impacto de la IA en la educación. Plataformas como Khan Academy utilizan algoritmos inteligentes para adaptar el contenido educativo a las necesidades individuales de cada estudiante, permitiéndoles avanzar a su propio ritmo y profundizar en áreas específicas. Esta personalización no solo mejora la experiencia educativa, sino que también maximiza el potencial de aprendizaje de cada alumno, brindando una educación más efectiva y enfocada.\n",
      "\n",
      "Además, la accesibilidad a la educación se ha visto notablemente mejorada gracias a la IA. Plataformas en línea como Coursera y edX ofrecen una amplia gama de cursos gratuitos o a precios accesibles, eliminando barreras geográficas y económicas para el aprendizaje. La IA también ha dado lugar a innovaciones como los asistentes virtuales y chatbots educativos, que proporcionan apoyo personalizado a los estudiantes y los guían de manera interactiva en su proceso de aprendizaje. Estas herramientas tecnológicas no solo amplían el acceso a la educación, sino que también mejoran la experiencia de aprendizaje de los estudiantes al ofrecer un acompañamiento constante y adaptado a sus necesidades individuales.\n",
      "\n",
      "Sin embargo, a pesar de los evidentes beneficios de la IA en la educación, surgen desafíos éticos y sociales que requieren una atención especial. Es crucial abordar la cuestión de la transparencia en el uso de la IA en el ámbito educativo, garantizar la equidad en el acceso a la educación y proteger la privacidad de los datos de los estudiantes. Asimismo, la automatización generada por la IA plantea interrogantes sobre el futuro del empleo en el sector educativo, lo que destaca la necesidad de una reflexión crítica sobre cómo preparar a educadores y estudiantes para los cambios tecnológicos en curso. En resumen, la inteligencia artificial está transformando el panorama educativo de manera profunda, ofreciendo nuevas oportunidades y desafíos que deben ser abordados con conciencia y equidad para garantizar un futuro educativo inclusivo y sostenible.\n",
      "\n",
      "🙋 Humano:\n",
      "¡Excelente ensayo sobre el impacto de la inteligencia artificial en la educación! Has desarrollado de manera clara y estructurada los beneficios y desafíos que presenta la IA en este ámbito. Aquí tienes algunas sugerencias para enriquecer aún más tu trabajo:\n",
      "\n",
      "1. **Refuerzo de argumentos con evidencia adicional**: Aunque has mencionado plataformas como Khan Academy, Coursera y edX como ejemplos de cómo la IA ha mejorado la personalización y accesibilidad educativa, podrías ampliar tus ejemplos con casos concretos de cómo estas plataformas utilizan la IA en la práctica. Incluir datos específicos y estudios de casos reforzará tus argumentos y brindará más solidez a tu ensayo.\n",
      "\n",
      "2. **Exploración de perspectivas críticas adicionales**: Para enriquecer tu análisis, podrías considerar incluir otras perspectivas críticas sobre el impacto de la IA en la educación. Por ejemplo, podrías profundizar en cómo la IA podría afectar la relación entre estudiantes y docentes, el desarrollo de habilidades socioemocionales o la participación de los padres en el proceso educativo en un entorno digitalizado.\n",
      "\n",
      "3. **Propuesta de soluciones o recomendaciones**: Sería útil finalizar tu ensayo con posibles soluciones o recomendaciones para abordar los desafíos éticos y sociales planteados por la IA en la educación. ¿Qué medidas específicas podrían tomarse para garantizar la transparencia, equidad y protección de datos en la implementación de la IA en las aulas?\n",
      "\n",
      "4. **Vocabulario y redacción**: Tu ensayo está bien redactado, pero asegúrate de mantener un estilo académico formal y de utilizar un vocabulario preciso y claro en todo momento. Revisa la coherencia en términos de voz y tiempos verbales para garantizar una comunicación fluida.\n",
      "\n",
      "En general, has elaborado un ensayo sólido y convincente. Continúa desarrollando tus ideas, respaldándolas con evidencia sólida y considerando diversas perspectivas para ofrecer un análisis completo sobre el tema. ¡Sigue adelante con tu excelente trabajo!\n",
      "\n",
      "🤖 AI:\n",
      "La inteligencia artificial (IA) ha dejado una marca significativa en el campo educativo, abriendo nuevas posibilidades y desafíos que requieren una consideración cuidadosa. Uno de los impactos más destacados de la IA en la educación es la personalización del aprendizaje. Plataformas como Khan Academy utilizan algoritmos inteligentes para adaptar el contenido educativo a las necesidades específicas de cada alumno, permitiéndoles avanzar a su propio ritmo y profundizar en áreas de mayor interés. Este enfoque personalizado no solo mejora la efectividad del aprendizaje, sino que también empodera a los estudiantes al ofrecerles un camino educativo único y ajustado a sus necesidades individuales.\n",
      "\n",
      "Además, la IA ha revolucionado la accesibilidad a la educación al eliminar barreras geográficas y económicas. Plataformas en línea como Coursera y edX ofrecen una variedad de cursos gratuitos o a precios asequibles, ampliando el acceso a la educación a una audiencia global. Además, la IA ha dado lugar a tecnologías innovadoras como los asistentes virtuales y chatbots educativos, que brindan apoyo personalizado a los alumnos y los guían de manera interactiva en su proceso de aprendizaje. Estas herramientas tecnológicas no solo enriquecen la experiencia educativa, sino que también fomentan la autonomía y la motivación de los estudiantes al brindarles un acompañamiento eficaz y adaptado a sus necesidades individuales.\n",
      "\n",
      "A pesar de los beneficios evidentes que aporta la IA a la educación, también plantea desafíos éticos y sociales que requieren atención. Es esencial abordar la cuestión de la transparencia en el uso de la IA en el ámbito educativo, garantizar la equidad en el acceso a la educación y proteger la privacidad de los datos de los estudiantes. Asimismo, la automatización generada por la IA puede plantear interrogantes sobre el futuro del empleo en el sector educativo, lo que destaca la importancia de preparar a educadores y estudiantes para los cambios tecnológicos en curso. En resumen, la inteligencia artificial está remodelando el panorama educativo de manera profunda y dinámica, ofreciendo oportunidades significativas si se abordan los desafíos de manera ética y equitativa para construir un futuro educativo inclusivo y sostenible.\n"
     ]
    }
   ],
   "source": [
    "# --- Ejecutar ejemplo ---\n",
    "entrada_inicial = {\n",
    "    \"messages\": [HumanMessage(content=\"Escribe un ensayo sobre el impacto de la inteligencia artificial en la educación\")]\n",
    "}\n",
    "\n",
    "estado_final = grafo.invoke(entrada_inicial)\n",
    "\n",
    "# --- Mostrar resultado ---\n",
    "print(\"📝 Resultado final:\")\n",
    "for msg in estado_final[\"messages\"]:\n",
    "    tipo = \"🤖 AI\" if isinstance(msg, AIMessage) else \"🙋 Humano\"\n",
    "    print(f\"\\n{tipo}:\\n{msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bb2458-9f14-4666-b4e0-32fcefe7fe29",
   "metadata": {},
   "source": [
    "\n",
    "Observa cómo el nodo de reflexión engaña al LLM haciéndole creer que está criticando ensayos escritos por el usuario. Y, de forma paralela, se hace que el nodo de generación piense que la crítica proviene del usuario. Este engaño es necesario porque los LLMs entrenados para diálogo están entrenados con pares de mensajes humano-IA, por lo que una secuencia con muchos mensajes del mismo participante daría como resultado un rendimiento deficiente.\n",
    "\n",
    "Un detalle más a tener en cuenta: podrías, a primera vista, esperar que el final ocurra después de un paso de revisión, pero en esta arquitectura tenemos un número **fijo** de iteraciones en el ciclo generar-reflexionar; por lo tanto, terminamos después de generar (para que el último conjunto de revisiones solicitadas sea atendido). Una variación de esta arquitectura permitiría que el paso de reflexión decidiera cuándo terminar el proceso (una vez que ya no tuviera más comentarios).\n",
    "\n",
    "Veamos cómo se ve una de las críticas:\n",
    "\n",
    "---\n",
    "\n",
    "Este tipo simple de reflexión puede, en ocasiones, mejorar el rendimiento al darle al LLM múltiples intentos de refinar su salida y al permitir que el nodo de reflexión adopte una **personalidad distinta** mientras critica el resultado.\n",
    "\n",
    "Hay varias posibles variaciones de esta arquitectura. Por ejemplo, podríamos combinar el paso de reflexión con la arquitectura de agentes del Capítulo 6, añadiéndolo como el último nodo justo antes de enviar la salida al usuario. Esto haría que la crítica pareciera provenir del usuario y le daría a la aplicación una oportunidad de mejorar su salida final sin intervención directa del usuario. Obviamente, este enfoque implicaría una mayor **latencia**.\n",
    "\n",
    "En ciertos casos de uso, podría ser útil fundamentar la crítica con información externa. Por ejemplo, si estuvieras construyendo un agente de generación de código, podrías tener un paso antes de reflexionar que ejecute el código a través de un *linter* o *compilador* y reporte cualquier error como entrada para la reflexión.\n",
    "\n",
    "💡 **CONSEJO**  \n",
    "Siempre que este enfoque sea posible, te recomendamos encarecidamente probarlo, ya que probablemente aumentará la calidad del resultado final.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3daa798-7854-4ce7-871f-c5525cf6fc4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Si solo quieres ver el **último mensaje generado** (el resultado final del ciclo de generación-reflexión), puedes modificar la última parte del código así:\n",
    "\n",
    "```python\n",
    "# Mostrar solo el último mensaje (el más reciente)\n",
    "ultimo_mensaje = estado_final[\"messages\"][-1]\n",
    "\n",
    "if isinstance(ultimo_mensaje, AIMessage):\n",
    "    print(\"📝 Último mensaje de la IA:\\n\")\n",
    "else:\n",
    "    print(\"🙋 Último mensaje del 'usuario':\\n\")\n",
    "\n",
    "print(ultimo_mensaje.content)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Esto imprimirá únicamente el contenido final, que dependiendo del número de iteraciones será:\n",
    "\n",
    "- Un ensayo si la última acción fue de la IA (`AIMessage`)\n",
    "- Una crítica si terminó en reflexión (`HumanMessage`)\n",
    "\n",
    "> 💡 Tip: En el flujo original, el ciclo siempre termina después de una **generación**, así que el último mensaje será una respuesta final mejorada del asistente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3815f1d-f798-4d30-a144-160db3e3a569",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Último mensaje de la IA:\n",
      "\n",
      "La inteligencia artificial (IA) ha dejado una marca significativa en el campo educativo, abriendo nuevas posibilidades y desafíos que requieren una consideración cuidadosa. Uno de los impactos más destacados de la IA en la educación es la personalización del aprendizaje. Plataformas como Khan Academy utilizan algoritmos inteligentes para adaptar el contenido educativo a las necesidades específicas de cada alumno, permitiéndoles avanzar a su propio ritmo y profundizar en áreas de mayor interés. Este enfoque personalizado no solo mejora la efectividad del aprendizaje, sino que también empodera a los estudiantes al ofrecerles un camino educativo único y ajustado a sus necesidades individuales.\n",
      "\n",
      "Además, la IA ha revolucionado la accesibilidad a la educación al eliminar barreras geográficas y económicas. Plataformas en línea como Coursera y edX ofrecen una variedad de cursos gratuitos o a precios asequibles, ampliando el acceso a la educación a una audiencia global. Además, la IA ha dado lugar a tecnologías innovadoras como los asistentes virtuales y chatbots educativos, que brindan apoyo personalizado a los alumnos y los guían de manera interactiva en su proceso de aprendizaje. Estas herramientas tecnológicas no solo enriquecen la experiencia educativa, sino que también fomentan la autonomía y la motivación de los estudiantes al brindarles un acompañamiento eficaz y adaptado a sus necesidades individuales.\n",
      "\n",
      "A pesar de los beneficios evidentes que aporta la IA a la educación, también plantea desafíos éticos y sociales que requieren atención. Es esencial abordar la cuestión de la transparencia en el uso de la IA en el ámbito educativo, garantizar la equidad en el acceso a la educación y proteger la privacidad de los datos de los estudiantes. Asimismo, la automatización generada por la IA puede plantear interrogantes sobre el futuro del empleo en el sector educativo, lo que destaca la importancia de preparar a educadores y estudiantes para los cambios tecnológicos en curso. En resumen, la inteligencia artificial está remodelando el panorama educativo de manera profunda y dinámica, ofreciendo oportunidades significativas si se abordan los desafíos de manera ética y equitativa para construir un futuro educativo inclusivo y sostenible.\n"
     ]
    }
   ],
   "source": [
    "# Mostrar solo el último mensaje (el más reciente)\n",
    "ultimo_mensaje = estado_final[\"messages\"][-1]\n",
    "\n",
    "if isinstance(ultimo_mensaje, AIMessage):\n",
    "    print(\"📝 Último mensaje de la IA:\\n\")\n",
    "else:\n",
    "    print(\"🙋 Último mensaje del 'usuario':\\n\")\n",
    "\n",
    "print(ultimo_mensaje.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e0436-42f9-480a-a886-25934e7c6d39",
   "metadata": {
    "tags": []
   },
   "source": [
    "Aquí va la traducción con los comentarios y cadenas de texto en el código también traducidos, pero sin tocar variables ni estructuras, como pediste:\n",
    "\n",
    "---\n",
    "\n",
    "### Subgrafos en LangGraph\n",
    "\n",
    "Antes de adentrarnos en arquitecturas multi-agente, veamos un concepto técnico importante en LangGraph que las hace posibles. Los subgrafos son grafos que se utilizan como parte de otro grafo. Aquí algunos casos de uso para los subgrafos:\n",
    "\n",
    "- Construcción de sistemas multi-agente (se discute en la siguiente sección).\n",
    "- Cuando quieres reutilizar un conjunto de nodos en múltiples grafos, puedes definirlos una vez en un subgrafo y luego usarlos en varios grafos principales.\n",
    "- Cuando diferentes equipos necesitan trabajar en diferentes partes del grafo de manera independiente, puedes definir cada parte como un subgrafo, y mientras se respete la interfaz del subgrafo (los esquemas de entrada y salida), el grafo principal puede construirse sin conocer los detalles del subgrafo.\n",
    "\n",
    "Hay dos maneras de añadir nodos de subgrafo a un grafo principal:\n",
    "\n",
    "**1. Agregar un nodo que llame directamente al subgrafo**  \n",
    "Esto es útil cuando el grafo principal y el subgrafo comparten claves de estado, y no necesitas transformar el estado ni al entrar ni al salir.\n",
    "\n",
    "**2. Agregar un nodo con una función que invoque el subgrafo**  \n",
    "Esto es útil cuando el grafo principal y el subgrafo tienen diferentes esquemas de estado, y necesitas transformar el estado antes o después de llamar al subgrafo.\n",
    "\n",
    "Veamos cada una por separado.\n",
    "\n",
    "---\n",
    "\n",
    "### Llamando a un Subgrafo Directamente\n",
    "\n",
    "La forma más simple de crear nodos de subgrafo es adjuntar un subgrafo directamente como un nodo. Al hacerlo, es importante que el grafo principal y el subgrafo compartan claves de estado, porque esas claves compartidas se usarán para comunicarse. (Si tu grafo y subgrafo no comparten ninguna clave, revisa la siguiente sección.)\n",
    "\n",
    "> **NOTA**  \n",
    "> Si pasas claves adicionales al nodo del subgrafo (es decir, además de las claves compartidas), serán ignoradas por el nodo del subgrafo. De manera similar, si el subgrafo devuelve claves adicionales, serán ignoradas por el grafo principal.\n",
    "\n",
    "Veamos cómo se ve esto en acción:\n",
    "\n",
    "---\n",
    "\n",
    "#### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bcca982-a53a-4ba1-8b9f-c1fa22d7bde5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'foo': 'hellobar'}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: str  # esta clave se comparte con el subgrafo\n",
    "\n",
    "class SubgraphState(TypedDict):\n",
    "    foo: str  # esta clave se comparte con el grafo principal\n",
    "    bar: str\n",
    "\n",
    "# Definir subgrafo\n",
    "def subgraph_node(state: SubgraphState):\n",
    "    # Este subgrafo puede comunicarse con el grafo principal a través de la clave \"foo\"\n",
    "    return {\"foo\": state[\"foo\"] + \"bar\"}\n",
    "\n",
    "# Crear el builder del subgrafo\n",
    "subgraph_builder = StateGraph(SubgraphState)\n",
    "\n",
    "subgraph_builder.add_node(\"subgraph_node\", subgraph_node)\n",
    "\n",
    "# Conectar el nodo 'START' al nodo 'subgraph_node'\n",
    "subgraph_builder.add_edge(START, \"subgraph_node\")\n",
    "# Compila el subgrafo\n",
    "subgraph = subgraph_builder.compile()\n",
    "\n",
    "# Definir grafo principal\n",
    "builder = StateGraph(State)\n",
    "# Agrega el subgrafo como un nodo en el grafo principal\n",
    "builder.add_node(\"subgraph\", subgraph)\n",
    "# Conectar el nodo 'START' al nodo 'subgraph' en el grafo principal\n",
    "builder.add_edge(START, \"subgraph\")\n",
    "# Aquí puedes agregar más nodos o configuraciones para el grafo principal si es necesario\n",
    "\n",
    "# Finalmente, compila el grafo principal\n",
    "graph = builder.compile()\n",
    "\n",
    "# Ahora, ejecutamos el grafo con un estado inicial\n",
    "state = {\"foo\": \"hello\"}\n",
    "result = graph.invoke(state)\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d41662a-82e1-4eb2-ab2d-ef24fb466bd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "### Llamar a un Subgrafo con una Función\n",
    "\n",
    "Puede que quieras definir un subgrafo con un esquema completamente diferente. En ese caso, puedes crear un nodo con una **función** que invoque al subgrafo. Esta función necesitará:\n",
    "\n",
    "1. Transformar el estado del grafo principal al estado requerido por el subgrafo **antes** de invocarlo.\n",
    "2. Transformar los resultados del subgrafo **de regreso** al estado del grafo principal antes de devolver la actualización de estado desde el nodo.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86495305-dfc7-4e10-a6e0-0a7dcfa9e3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e204621-ec33-45d2-b034-106023b756c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'foo': 'hellobaz'}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "from typing import TypedDict\n",
    "\n",
    "# Estado del grafo principal\n",
    "class ParentState(TypedDict):\n",
    "    foo: str\n",
    "\n",
    "# Estado del subgrafo\n",
    "class SubgraphState(TypedDict):\n",
    "    bar: str\n",
    "\n",
    "# Subgrafo que trabaja sobre SubgraphState\n",
    "def subgraph_node(state: SubgraphState):\n",
    "    return {\"bar\": state[\"bar\"] + \"baz\"}\n",
    "\n",
    "subgraph_builder = StateGraph(SubgraphState)\n",
    "subgraph_builder.add_node(\"sub_node\", subgraph_node)\n",
    "subgraph_builder.add_edge(START, \"sub_node\")\n",
    "subgraph = subgraph_builder.compile()\n",
    "\n",
    "# Nodo del grafo principal que llama al subgrafo\n",
    "def subgraph_caller(state: ParentState):\n",
    "    # Transformar estado del grafo principal al del subgrafo\n",
    "    sub_state = {\"bar\": state[\"foo\"]}\n",
    "    # Ejecutar el subgrafo\n",
    "    result = subgraph.invoke(sub_state)\n",
    "    # Transformar resultado de regreso al estado del grafo principal\n",
    "    return {\"foo\": result[\"bar\"]}\n",
    "\n",
    "# Construcción del grafo principal\n",
    "parent_builder = StateGraph(ParentState)\n",
    "parent_builder.add_node(\"call_subgraph\", subgraph_caller)\n",
    "parent_builder.add_edge(START, \"call_subgraph\")\n",
    "graph = parent_builder.compile()\n",
    "\n",
    "# Probarlo\n",
    "result = graph.invoke({\"foo\": \"hello\"})\n",
    "print(result)  # {'foo': 'hellobaz'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55652d32-1edb-4ae5-bad8-f173e27bc91b",
   "metadata": {},
   "source": [
    "\n",
    "### Ahora que sabemos cómo usar subgrafos, veamos uno de sus grandes casos de uso: **arquitecturas multiagente**.\n",
    "\n",
    "## Arquitecturas Multiagente\n",
    "\n",
    "A medida que los agentes basados en LLMs (modelos de lenguaje grandes) crecen en tamaño, alcance o complejidad, pueden surgir varios problemas que afectan su rendimiento, como los siguientes:\n",
    "\n",
    "- El agente recibe demasiadas herramientas para elegir y toma malas decisiones sobre cuál usar a continuación (el Capítulo 6 discutió algunos enfoques para este problema).\n",
    "- El contexto se vuelve demasiado complejo para que un solo agente lo mantenga bajo control; es decir, el tamaño de los *prompts* y la cantidad de cosas mencionadas superan la capacidad del modelo que estás usando.\n",
    "- Quieres usar un subsistema especializado para una tarea en particular, por ejemplo: planeación, investigación, resolución de problemas matemáticos, etc.\n",
    "\n",
    "Para abordar estos problemas, puedes considerar dividir tu aplicación en múltiples agentes pequeños e independientes, y componerlos en un sistema multiagente. Estos agentes pueden ser tan simples como un *prompt* con una llamada a un LLM o tan complejos como un agente tipo ReAct (introducido en el Capítulo 6). \n",
    "\n",
    "La **Figura 7-3** ilustra varias formas de conectar agentes en un sistema multiagente.\n",
    "\n",
    "---\n",
    "\n",
    "### Figura 7-3. Múltiples estrategias para coordinar múltiples agentes\n",
    "\n",
    "Veamos con más detalle la Figura 7-3:\n",
    "\n",
    "- **Red (Network)**  \n",
    "  Cada agente puede comunicarse con todos los demás. Cualquier agente puede decidir cuál se ejecutará a continuación.\n",
    "\n",
    "- **Supervisor**  \n",
    "  Cada agente se comunica con un único agente llamado *supervisor*. El supervisor toma decisiones sobre qué agente (o agentes) deben llamarse a continuación. Un caso especial de esta arquitectura implementa el supervisor como una llamada a un LLM con herramientas (cubierto en el Capítulo 6).\n",
    "\n",
    "- **Jerárquica (Hierarchical)**  \n",
    "  Puedes definir un sistema multiagente con un supervisor de supervisores. Esta es una generalización de la arquitectura de supervisor y permite flujos de control más complejos.\n",
    "\n",
    "- **Flujo personalizado (Custom multi-agent workflow)**  \n",
    "  Cada agente se comunica solo con un subconjunto de agentes. Partes del flujo son deterministas, y solo algunos agentes pueden decidir qué otros agentes llamar.\n",
    "\n",
    "---\n",
    "\n",
    "La siguiente sección profundiza en la arquitectura de tipo **supervisor**, que ofrece un buen equilibrio entre capacidad y facilidad de uso.\n",
    "\n",
    "---\n",
    "\n",
    "## Arquitectura de Supervisor\n",
    "\n",
    "En esta arquitectura, añadimos cada agente al grafo como un nodo y también agregamos un nodo supervisor, que decide qué agentes deben llamarse a continuación. Usamos **bordes condicionales** (*conditional edges*) para dirigir la ejecución al nodo de agente apropiado con base en la decisión del supervisor. Puedes consultar el Capítulo 5 para una introducción a LangGraph, donde se abordan los conceptos de nodos, bordes y más.\n",
    "\n",
    "---\n",
    "\n",
    "### Primero veamos cómo se ve el nodo supervisor:\n",
    "\n",
    "**Python**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1224d405-66b3-475b-9c08-378f267faf53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class SupervisorDecision(BaseModel):\n",
    "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = model.with_structured_output(SupervisorDecision)\n",
    "\n",
    "agents = [\"researcher\", \"coder\"]\n",
    "\n",
    "system_prompt_part_1 = f\"\"\"You are a supervisor tasked with managing a \n",
    "conversation between the following workers: {agents}. Given the following user \n",
    "request, respond with the worker to act next. Each worker will perform a\n",
    "task and respond with their results and status. When finished,\n",
    "respond with FINISH.\"\"\"\n",
    "\n",
    "system_prompt_part_2 = f\"\"\"Given the conversation above, who should act next? Or \n",
    "    should we FINISH? Select one of: {', '.join(agents)}, FINISH\"\"\"\n",
    "\n",
    "def supervisor(state):\n",
    "    messages = [\n",
    "        (\"system\", system_prompt_part_1),\n",
    "        *state[\"messages\"],\n",
    "        (\"system\", \tsystem_prompt_part_2)\n",
    "    ]\n",
    "    return model.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd27b6e1-99e6-407c-be94-2fee5bd8fded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57f2e527-20de-494b-96f2-2cc042214242",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**NOTA**  \n",
    "El código en el prompt requiere que los nombres de tus subagentes sean autoexplicativos y distintos. Por ejemplo, si simplemente se llamaran `agente_1` y `agente_2`, el modelo LLM no tendría información suficiente para decidir cuál es el adecuado para cada tarea. Si es necesario, puedes modificar el prompt para añadir una descripción de cada agente, lo cual podría ayudar al LLM a elegir un agente para cada consulta.\n",
    "\n",
    "Ahora veamos cómo integrar este nodo supervisor en un grafo más grande que incluya a otros dos subagentes, a los que llamaremos `investigador` (researcher) y `programador` (coder).  \n",
    "Nuestro objetivo general con este grafo es manejar consultas que puedan ser respondidas ya sea por el investigador, el programador, o incluso por ambos en sucesión.  \n",
    "\n",
    "Este ejemplo no incluye la implementación del investigador o el programador—la idea clave es que podrían ser cualquier otro nodo o subgrafo de LangGraph.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab643f76-41e4-4a77-a733-aa6c95bc5b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import MessagesState\n",
    "\n",
    "# Clase para que el supervisor decida\n",
    "class SupervisorDecision(BaseModel):\n",
    "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]\n",
    "\n",
    "# Modelo con salida estructurada\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = model.with_structured_output(SupervisorDecision)\n",
    "\n",
    "# Agentes disponibles\n",
    "agents = [\"researcher\", \"coder\"]\n",
    "\n",
    "# Prompts del supervisor\n",
    "system_prompt_part_1 = f\"\"\"You are a supervisor tasked with managing a \n",
    "conversation between the following workers: {agents}. Given the following user \n",
    "request, respond with the worker to act next. Each worker will perform a\n",
    "task and respond with their results and status. When finished,\n",
    "respond with FINISH.\"\"\"\n",
    "\n",
    "system_prompt_part_2 = f\"\"\"Given the conversation above, who should act next? Or \n",
    "should we FINISH? Select one of: {', '.join(agents)}, FINISH\"\"\"\n",
    "\n",
    "# Nodo supervisor\n",
    "def supervisor(state):\n",
    "    messages = [\n",
    "        (\"system\", system_prompt_part_1),\n",
    "        *state[\"messages\"],\n",
    "        (\"system\", system_prompt_part_2)\n",
    "    ]\n",
    "    result = model.invoke(messages)\n",
    "    return {\"next\": result.next}\n",
    "\n",
    "# Definimos el estado compartido entre agentes\n",
    "class AgentState(BaseModel):\n",
    "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]\n",
    "\n",
    "# Nodo para el agente 'researcher'\n",
    "def researcher(state: AgentState):\n",
    "    response = model.invoke(\"Haz una investigación sobre el tema solicitado.\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Nodo para el agente 'coder'\n",
    "def coder(state: AgentState):\n",
    "    response = model.invoke(\"Escribe un fragmento de código para la tarea dada.\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Construcción del grafo\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"supervisor\", supervisor)\n",
    "builder.add_node(\"researcher\", researcher)\n",
    "builder.add_node(\"coder\", coder)\n",
    "\n",
    "# Enlaces del grafo\n",
    "builder.set_entry_point(\"supervisor\")\n",
    "builder.add_conditional_edges(\"supervisor\", lambda state: state[\"next\"], {\n",
    "    \"researcher\": \"researcher\",\n",
    "    \"coder\": \"coder\",\n",
    "    \"FINISH\": END,\n",
    "})\n",
    "\n",
    "builder.add_edge(\"researcher\", \"supervisor\")\n",
    "builder.add_edge(\"coder\", \"supervisor\")\n",
    "\n",
    "# Compilar el grafo\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2553cc8-32a0-4eec-813f-ca4b33d39430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Literal, Annotated\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import MessagesState\n",
    "\n",
    "# 1. Modelo del supervisor con salida estructurada\n",
    "class SupervisorDecision(BaseModel):\n",
    "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]\n",
    "\n",
    "# 2. Agentes disponibles\n",
    "agents = [\"researcher\", \"coder\"]\n",
    "\n",
    "# 3. Instanciar modelos\n",
    "supervisor_model = ChatOpenAI(model=\"gpt-4o\", temperature=0).with_structured_output(SupervisorDecision)\n",
    "agent_model = ChatOpenAI(model=\"gpt-4o\", temperature=0.3)  # Más libre para responder creativamente\n",
    "\n",
    "\n",
    "# 4. Prompt del supervisor\n",
    "system_prompt_part_1 = f\"\"\"You are a supervisor tasked with managing a \n",
    "conversation between the following workers: {agents}. Given the following user \n",
    "request, respond with the worker to act next. Each worker will perform a\n",
    "task and respond with their results and status. When finished,\n",
    "respond with FINISH.\"\"\"\n",
    "\n",
    "system_prompt_part_2 = f\"\"\"\n",
    "Dada la conversación anterior, decide quién debe actuar a continuación. Si el usuario ya ha recibido una respuesta completa y no hay más acciones necesarias, responde únicamente con: FINISH.\n",
    "\n",
    "Importante:\n",
    "- No reinicies el proceso si ya se respondió el tema central.\n",
    "- No repitas pasos innecesarios.\n",
    "- Elige solo una de las siguientes opciones: {', '.join(agents)}, FINISH.\n",
    "\"\"\"\n",
    "\n",
    "# 5. Nodo supervisor\n",
    "def supervisor(state: MessagesState):\n",
    "    messages = [\n",
    "        (\"system\", system_prompt_part_1),\n",
    "        *state[\"messages\"],\n",
    "        (\"system\", system_prompt_part_2)\n",
    "    ]\n",
    "    print(\":::::::::::::::::::::::::::::::::\", messages)\n",
    "    \n",
    "    print()\n",
    "    result = supervisor_model.invoke(messages)\n",
    "    \n",
    "    print(\"supervisor\", result.next)\n",
    "    return {\"next\": result.next}\n",
    "\n",
    "# 6. Nodo researcher\n",
    "def researcher(state: MessagesState):\n",
    "    messages =  state[\"messages\"][0].content  # solo tomamos el mensaje inicial\n",
    "    print(\"---------------------------\", messages)\n",
    "    print()\n",
    "\n",
    "    response = agent_model.invoke([HumanMessage(content=f\"Haz una investigación sobre este tema : {messages}\")])\n",
    "    return {\"messages\": state[\"messages\"] +  [response]}\n",
    "\n",
    "# 7. Nodo coder\n",
    "def coder(state: MessagesState):\n",
    "    messages =  state[\"messages\"][0].content  # solo tomamos el mensaje inicial\n",
    "    response = agent_model.invoke([HumanMessage(content=f\"Escribe un fragmento de código para este tema: {messages}\")])\n",
    "    return {\"messages\":  state[\"messages\"] +  [response]}\n",
    "# 8. Construcción del grafo\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"supervisor\", supervisor)\n",
    "builder.add_node(\"researcher\", researcher)\n",
    "builder.add_node(\"coder\", coder)\n",
    "\n",
    "builder.set_entry_point(\"supervisor\")\n",
    "\n",
    "builder.add_conditional_edges(\"supervisor\", lambda state: state[\"next\"], {\n",
    "    \"researcher\": \"researcher\",\n",
    "    \"coder\": \"coder\",\n",
    "    \"FINISH\": END,\n",
    "})\n",
    "\n",
    "builder.add_edge(\"researcher\", \"supervisor\")\n",
    "builder.add_edge(\"coder\", \"supervisor\")\n",
    "\n",
    "# 9. Compilar el grafo\n",
    "graph = builder.compile()\n",
    "\n",
    "# 10. Función para correr el grafo\n",
    "def run_graph_with_prompt(user_prompt: str):\n",
    "    input_state = {\"messages\": [HumanMessage(content=user_prompt)]}\n",
    "\n",
    "    for step_name in graph.stream(input_state):\n",
    "        print(f\"\\n>>> Paso: {step_name}\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c0226a8-c1f6-4777-9279-eef5cc1497e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::::::::::::::::::::::::::::::::: [('system', \"You are a supervisor tasked with managing a \\nconversation between the following workers: ['researcher', 'coder']. Given the following user \\nrequest, respond with the worker to act next. Each worker will perform a\\ntask and respond with their results and status. When finished,\\nrespond with FINISH.\"), HumanMessage(content='Necesito ayuda para una investigación sobre el cambio climático.', additional_kwargs={}, response_metadata={}, id='fd7b0013-b11e-4d66-9a45-43b7e482f7af'), ('system', '\\nDada la conversación anterior, decide quién debe actuar a continuación. Si el usuario ya ha recibido una respuesta completa y no hay más acciones necesarias, responde únicamente con: FINISH.\\n\\nImportante:\\n- No reinicies el proceso si ya se respondió el tema central.\\n- No repitas pasos innecesarios.\\n- Elige solo una de las siguientes opciones: researcher, coder, FINISH.\\n')]\n",
      "\n",
      "supervisor researcher\n",
      "\n",
      ">>> Paso: {'supervisor': None}\n",
      "--------------------------- Necesito ayuda para una investigación sobre el cambio climático.\n",
      "\n",
      "\n",
      ">>> Paso: {'researcher': {'messages': [HumanMessage(content='Necesito ayuda para una investigación sobre el cambio climático.', additional_kwargs={}, response_metadata={}, id='fd7b0013-b11e-4d66-9a45-43b7e482f7af'), AIMessage(content='El cambio climático es uno de los desafíos más importantes y urgentes que enfrenta la humanidad en el siglo XXI. A continuación, te proporciono una guía básica sobre los aspectos clave que podrías investigar para desarrollar un trabajo completo sobre este tema:\\n\\n### 1. **Definición y Causas del Cambio Climático**\\n   - **Definición:** El cambio climático se refiere a las variaciones a largo plazo en las temperaturas y los patrones climáticos de la Tierra. Aunque estos cambios pueden ser naturales, desde el siglo XIX, las actividades humanas han sido el principal impulsor del cambio climático, principalmente debido a la quema de combustibles fósiles como el carbón, el petróleo y el gas.\\n   - **Causas Principales:**\\n     - **Gases de Efecto Invernadero (GEI):** El dióxido de carbono (CO2), el metano (CH4) y el óxido nitroso (N2O) son los principales GEI que contribuyen al calentamiento global.\\n     - **Deforestación:** La tala de bosques reduce la capacidad de la Tierra para absorber CO2.\\n     - **Agricultura y Ganadería:** Estas actividades emiten metano y otros GEI.\\n\\n### 2. **Impactos del Cambio Climático**\\n   - **Ecosistemas y Biodiversidad:** Cambios en los hábitats, extinción de especies, y alteración de los ciclos naturales.\\n   - **Fenómenos Meteorológicos Extremos:** Aumento en la frecuencia e intensidad de huracanes, sequías, inundaciones y olas de calor.\\n   - **Nivel del Mar:** El derretimiento de los glaciares y el hielo polar contribuye al aumento del nivel del mar, amenazando a las comunidades costeras.\\n   - **Salud Humana:** Aumento de enfermedades relacionadas con el calor, problemas respiratorios por la contaminación del aire, y propagación de enfermedades transmitidas por vectores.\\n\\n### 3. **Mitigación y Adaptación**\\n   - **Mitigación:** Acciones para reducir o prevenir la emisión de GEI. Esto incluye el uso de energías renovables, eficiencia energética, y reforestación.\\n   - **Adaptación:** Ajustes en sistemas humanos o naturales en respuesta a los efectos del cambio climático. Ejemplos incluyen la construcción de infraestructuras resistentes al clima y el desarrollo de cultivos resistentes a la sequía.\\n\\n### 4. **Políticas y Acuerdos Internacionales**\\n   - **Protocolo de Kioto:** Un acuerdo internacional que establece compromisos vinculantes para reducir las emisiones de GEI.\\n   - **Acuerdo de París:** Un pacto global para limitar el calentamiento global a menos de 2 grados Celsius por encima de los niveles preindustriales, con esfuerzos para limitarlo a 1.5 grados.\\n\\n### 5. **Rol de la Ciencia y la Tecnología**\\n   - **Investigación Científica:** Modelos climáticos, estudios de impacto, y monitoreo de cambios ambientales.\\n   - **Innovación Tecnológica:** Desarrollo de tecnologías limpias, captura y almacenamiento de carbono, y geoingeniería.\\n\\n### 6. **Participación Ciudadana y Educación**\\n   - **Conciencia Pública:** Educación sobre el cambio climático y sus impactos.\\n   - **Acciones Comunitarias:** Iniciativas locales para reducir la huella de carbono y promover la sostenibilidad.\\n\\n### 7. **Desafíos y Oportunidades**\\n   - **Desafíos:** Resistencia política, desigualdad en la responsabilidad y los impactos, y la necesidad de una transición justa.\\n   - **Oportunidades:** Desarrollo de economías verdes, creación de empleos sostenibles, y mejora de la calidad de vida.\\n\\nPara una investigación más detallada, podrías centrarte en un aspecto específico del cambio climático, como el impacto en una región particular, el papel de una industria específica en las emisiones de GEI, o las políticas de un país en particular. Además, es importante consultar fuentes académicas, informes de organizaciones internacionales como el IPCC (Panel Intergubernamental sobre Cambio Climático), y datos de agencias meteorológicas y ambientales.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 860, 'prompt_tokens': 25, 'total_tokens': 885, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BOg7Tn7fcNwQ0gsWs11UZcL7tuNY2', 'finish_reason': 'stop', 'logprobs': None}, id='run-e0e68ddc-da96-48ed-b80c-347b63ef75e6-0', usage_metadata={'input_tokens': 25, 'output_tokens': 860, 'total_tokens': 885, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "::::::::::::::::::::::::::::::::: [('system', \"You are a supervisor tasked with managing a \\nconversation between the following workers: ['researcher', 'coder']. Given the following user \\nrequest, respond with the worker to act next. Each worker will perform a\\ntask and respond with their results and status. When finished,\\nrespond with FINISH.\"), HumanMessage(content='Necesito ayuda para una investigación sobre el cambio climático.', additional_kwargs={}, response_metadata={}, id='fd7b0013-b11e-4d66-9a45-43b7e482f7af'), AIMessage(content='El cambio climático es uno de los desafíos más importantes y urgentes que enfrenta la humanidad en el siglo XXI. A continuación, te proporciono una guía básica sobre los aspectos clave que podrías investigar para desarrollar un trabajo completo sobre este tema:\\n\\n### 1. **Definición y Causas del Cambio Climático**\\n   - **Definición:** El cambio climático se refiere a las variaciones a largo plazo en las temperaturas y los patrones climáticos de la Tierra. Aunque estos cambios pueden ser naturales, desde el siglo XIX, las actividades humanas han sido el principal impulsor del cambio climático, principalmente debido a la quema de combustibles fósiles como el carbón, el petróleo y el gas.\\n   - **Causas Principales:**\\n     - **Gases de Efecto Invernadero (GEI):** El dióxido de carbono (CO2), el metano (CH4) y el óxido nitroso (N2O) son los principales GEI que contribuyen al calentamiento global.\\n     - **Deforestación:** La tala de bosques reduce la capacidad de la Tierra para absorber CO2.\\n     - **Agricultura y Ganadería:** Estas actividades emiten metano y otros GEI.\\n\\n### 2. **Impactos del Cambio Climático**\\n   - **Ecosistemas y Biodiversidad:** Cambios en los hábitats, extinción de especies, y alteración de los ciclos naturales.\\n   - **Fenómenos Meteorológicos Extremos:** Aumento en la frecuencia e intensidad de huracanes, sequías, inundaciones y olas de calor.\\n   - **Nivel del Mar:** El derretimiento de los glaciares y el hielo polar contribuye al aumento del nivel del mar, amenazando a las comunidades costeras.\\n   - **Salud Humana:** Aumento de enfermedades relacionadas con el calor, problemas respiratorios por la contaminación del aire, y propagación de enfermedades transmitidas por vectores.\\n\\n### 3. **Mitigación y Adaptación**\\n   - **Mitigación:** Acciones para reducir o prevenir la emisión de GEI. Esto incluye el uso de energías renovables, eficiencia energética, y reforestación.\\n   - **Adaptación:** Ajustes en sistemas humanos o naturales en respuesta a los efectos del cambio climático. Ejemplos incluyen la construcción de infraestructuras resistentes al clima y el desarrollo de cultivos resistentes a la sequía.\\n\\n### 4. **Políticas y Acuerdos Internacionales**\\n   - **Protocolo de Kioto:** Un acuerdo internacional que establece compromisos vinculantes para reducir las emisiones de GEI.\\n   - **Acuerdo de París:** Un pacto global para limitar el calentamiento global a menos de 2 grados Celsius por encima de los niveles preindustriales, con esfuerzos para limitarlo a 1.5 grados.\\n\\n### 5. **Rol de la Ciencia y la Tecnología**\\n   - **Investigación Científica:** Modelos climáticos, estudios de impacto, y monitoreo de cambios ambientales.\\n   - **Innovación Tecnológica:** Desarrollo de tecnologías limpias, captura y almacenamiento de carbono, y geoingeniería.\\n\\n### 6. **Participación Ciudadana y Educación**\\n   - **Conciencia Pública:** Educación sobre el cambio climático y sus impactos.\\n   - **Acciones Comunitarias:** Iniciativas locales para reducir la huella de carbono y promover la sostenibilidad.\\n\\n### 7. **Desafíos y Oportunidades**\\n   - **Desafíos:** Resistencia política, desigualdad en la responsabilidad y los impactos, y la necesidad de una transición justa.\\n   - **Oportunidades:** Desarrollo de economías verdes, creación de empleos sostenibles, y mejora de la calidad de vida.\\n\\nPara una investigación más detallada, podrías centrarte en un aspecto específico del cambio climático, como el impacto en una región particular, el papel de una industria específica en las emisiones de GEI, o las políticas de un país en particular. Además, es importante consultar fuentes académicas, informes de organizaciones internacionales como el IPCC (Panel Intergubernamental sobre Cambio Climático), y datos de agencias meteorológicas y ambientales.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 860, 'prompt_tokens': 25, 'total_tokens': 885, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BOg7Tn7fcNwQ0gsWs11UZcL7tuNY2', 'finish_reason': 'stop', 'logprobs': None}, id='run-e0e68ddc-da96-48ed-b80c-347b63ef75e6-0', usage_metadata={'input_tokens': 25, 'output_tokens': 860, 'total_tokens': 885, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ('system', '\\nDada la conversación anterior, decide quién debe actuar a continuación. Si el usuario ya ha recibido una respuesta completa y no hay más acciones necesarias, responde únicamente con: FINISH.\\n\\nImportante:\\n- No reinicies el proceso si ya se respondió el tema central.\\n- No repitas pasos innecesarios.\\n- Elige solo una de las siguientes opciones: researcher, coder, FINISH.\\n')]\n",
      "\n",
      "supervisor researcher\n",
      "\n",
      ">>> Paso: {'supervisor': None}\n",
      "--------------------------- Necesito ayuda para una investigación sobre el cambio climático.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_118/479827556.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_graph_with_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Necesito ayuda para una investigación sobre el cambio climático.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_118/1165636977.py\u001b[0m in \u001b[0;36mrun_graph_with_prompt\u001b[0;34m(user_prompt)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0minput_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n>>> Paso: {step_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2375\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2376\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2377\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2378\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2379\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    159\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_118/1165636977.py\u001b[0m in \u001b[0;36mresearcher\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Haz una investigación sobre este tema : {messages}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m         return cast(\n\u001b[1;32m    367\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    369\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    936\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m                 results.append(\n\u001b[0;32m--> 759\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    760\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1003\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             )\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    989\u001b[0m             \u001b[0mgeneration_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    927\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    928\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             body=maybe_transform(\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m         )\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     def patch(\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    950\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m    990\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    231\u001b[0m         )\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    197\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     )\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    114\u001b[0m                 trace.return_value = (\n\u001b[1;32m    115\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    225\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 )\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1258\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1260\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1133\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_graph_with_prompt(\"Necesito ayuda para una investigación sobre el cambio climático.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ed346e-3024-4195-ae92-7c7ec6ed8a4b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Algunas cosas a notar:\n",
    "\n",
    "En este ejemplo, ambos subagentes (**researcher** y **coder**) pueden ver el trabajo del otro, ya que todo el progreso se guarda en la lista de `messages`. Pero **no es la única forma** de organizar esto. Cada uno de los subagentes podría ser más complejo. Por ejemplo, un subagente podría ser su propio grafo que mantenga un estado interno y solo saque un resumen de lo que hizo.\n",
    "\n",
    "Después de que cada agente actúe, volvemos al nodo **supervisor**, que decide si queda algo por hacer y a cuál agente delegárselo. Pero este enrutamiento **no es obligatorio** en esta arquitectura. También podrías hacer que cada subagente decida si su salida se regresa directamente al usuario. Para eso, tendrías que reemplazar la conexión directa entre, por ejemplo, `researcher` y `supervisor`, por una conexión condicional (que lea una clave del estado actualizada por `researcher`).\n",
    "\n",
    "---\n",
    "\n",
    "### Resumen:\n",
    "\n",
    "Este capítulo cubre dos extensiones importantes para la arquitectura de agentes:\n",
    "- **Reflexión**\n",
    "- **Arquitecturas multiagente**\n",
    "\n",
    "También vimos cómo trabajar con **subgrafos** en LangGraph, que son un componente clave en estos sistemas multiagente.\n",
    "\n",
    "Estas extensiones le dan más poder a la arquitectura basada en agentes con LLM, pero **no deberían ser lo primero que uses** cuando crees un agente nuevo. Lo mejor es empezar con la arquitectura directa explicada en el **Capítulo 6**.\n",
    "\n",
    "---\n",
    "\n",
    "### Lo que viene (Capítulo 8):\n",
    "\n",
    "Regresamos al dilema entre **confiabilidad** y **agencia**, que es una decisión crítica al construir apps con LLM hoy en día. Esto se vuelve aún más importante cuando usas arquitecturas de agentes o multiagentes, ya que su poder puede traer caos si no lo controlas. En el capítulo siguiente se explican técnicas clave para manejar esta decisión y **mejorar tus agentes y aplicaciones**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84529fc0-5d29-42ef-bc52-80488dd4b512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
