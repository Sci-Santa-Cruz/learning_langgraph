{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "936e324b-bcb7-4244-81f0-8bd98f9e7b3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = key  # reemplaza con tu clave real si es necesario\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb820559-c858-4761-ac90-9129847c33b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da56f6d2-8338-494d-8441-9826880d8b51",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Capítulo 6. Arquitectura de Agentes\n",
    "\n",
    "Basándonos en las arquitecturas descritas en el Capítulo 5, este capítulo cubrirá lo que quizá sea la más importante de todas las arquitecturas actuales de modelos de lenguaje grande (LLM): la arquitectura de agentes. Primero, presentaremos qué hace únicos a los agentes con LLM, luego mostraremos cómo construirlos y cómo extenderlos para casos de uso comunes.\n",
    "\n",
    "En el campo de la inteligencia artificial, existe una larga historia en la creación de agentes (inteligentes), que pueden definirse de forma sencilla como “algo que actúa”, en palabras de Stuart Russell y Peter Norvig en su libro *Artificial Intelligence* (Pearson, 2020). La palabra *actúa* tiene más implicaciones de lo que parece a simple vista:\n",
    "\n",
    "- Actuar requiere cierta capacidad para decidir qué hacer.\n",
    "- Decidir qué hacer implica tener más de una posible acción. Después de todo, una decisión sin opciones no es una decisión.\n",
    "- Para decidir, el agente también necesita información sobre el entorno externo (cualquier cosa fuera del propio agente).\n",
    "\n",
    "Así que una aplicación LLM con arquitectura de agente debe ser aquella que utiliza un modelo LLM para elegir entre una o más posibles acciones, dadas ciertas condiciones del estado actual del mundo o un estado deseado. Estas capacidades suelen implementarse combinando dos técnicas de \"prompting\" que ya conocimos en el prefacio:\n",
    "\n",
    "**Uso de herramientas**  \n",
    "Incluye en el prompt una lista de funciones externas que el LLM puede utilizar (es decir, las acciones que puede decidir tomar), junto con instrucciones sobre cómo debe formatear su elección en la salida. En breve veremos cómo se ve esto en un prompt.\n",
    "\n",
    "**Cadena de razonamiento (chain-of-thought)**  \n",
    "Los investigadores han descubierto que los LLMs “toman mejores decisiones” cuando se les da instrucciones para razonar sobre problemas complejos dividiéndolos en pasos secuenciales. Esto suele hacerse con frases como “piensa paso a paso” o mostrando ejemplos de preguntas divididas en varios pasos o acciones.\n",
    "\n",
    "Aquí tienes un ejemplo de prompt que combina el uso de herramientas y la cadena de razonamiento:\n",
    "\n",
    "---\n",
    "\n",
    "**Herramientas:**  \n",
    "- `search`: esta herramienta acepta una consulta de búsqueda web y devuelve los resultados principales.  \n",
    "- `calculator`: esta herramienta acepta expresiones matemáticas y devuelve su resultado.  \n",
    "\n",
    "Si deseas usar herramientas para llegar a la respuesta, escribe la lista de herramientas e insumos en formato CSV, con la fila de encabezado: `tool,input`.\n",
    "\n",
    "Piensa paso a paso; si necesitas usar varias herramientas para llegar a la respuesta, devuelve solo la primera.\n",
    "\n",
    "**Pregunta:**  \n",
    "¿Cuántos años tenía el 30º presidente de los Estados Unidos cuando murió?\n",
    "\n",
    "**Respuesta esperada:**  \n",
    "tool,input\n",
    "\n",
    "---\n",
    "\n",
    "Y la salida, cuando se ejecuta con `gpt-3.5-turbo` a temperatura 0 (para asegurar que el modelo siga el formato CSV esperado) y con salto de línea como secuencia de parada (lo que indica al modelo que deje de generar texto al llegar a ese carácter). Esto hace que el LLM produzca una sola acción (como se esperaba, dado el prompt):\n",
    "\n",
    "```\n",
    "search,30th president of the United States\n",
    "```\n",
    "\n",
    "Los modelos más recientes han sido ajustados para mejorar su desempeño en tareas de uso de herramientas y cadena de razonamiento, eliminando la necesidad de instrucciones específicas en el prompt.\n",
    "\n",
    "---\n",
    "\n",
    "## El Bucle Planificar-Hacer (Plan-Do Loop)\n",
    "\n",
    "Lo que distingue a la arquitectura de agentes de las descritas en el Capítulo 5 es un concepto que aún no habíamos tratado: el bucle controlado por el LLM.\n",
    "\n",
    "Todo programador ha visto bucles en su código. Por bucle, nos referimos a ejecutar el mismo código varias veces hasta que se cumpla una condición de parada. La clave en la arquitectura de agentes es que el propio LLM controle esta condición: es decir, que decida cuándo dejar de iterar.\n",
    "\n",
    "El ciclo que se ejecuta incluye generalmente:\n",
    "\n",
    "- Planificar una o varias acciones\n",
    "- Ejecutar dichas acciones\n",
    "\n",
    "Retomando el ejemplo anterior, ahora ejecutamos la herramienta `search` con la entrada *30th president of the United States*, que produce esta salida:\n",
    "\n",
    "> Calvin Coolidge (nacido como John Calvin Coolidge Jr.; 4 de julio de 1872 – 5 de enero de 1933) fue un abogado y político estadounidense que se desempeñó como el 30º presidente de los Estados Unidos de 1923 a 1929.\n",
    "\n",
    "Luego volvemos a ejecutar el prompt, con una pequeña adición:\n",
    "\n",
    "---\n",
    "\n",
    "**Herramientas:**  \n",
    "- `search`: consulta en la web.  \n",
    "- `calculator`: evalúa expresiones matemáticas.  \n",
    "- `output`: finaliza la interacción. Úsala cuando tengas la respuesta final.\n",
    "\n",
    "Si necesitas herramientas para llegar a la respuesta, escribe la lista en formato CSV, con el encabezado: `tool,input`.\n",
    "\n",
    "Piensa paso a paso; si necesitas múltiples pasos, regresa solo el primero.\n",
    "\n",
    "**Pregunta:**  \n",
    "¿Cuántos años tenía el 30º presidente de los Estados Unidos cuando murió?\n",
    "\n",
    "**Respuesta esperada:**\n",
    "\n",
    "```\n",
    "tool,input  \n",
    "search,30th president of the United States  \n",
    "```\n",
    "\n",
    "**Resultado de `search`:**  \n",
    "Calvin Coolidge (nacido como John Calvin Coolidge Jr.; 4 de julio de 1872 – 5 de enero de 1933)...\n",
    "\n",
    "**Siguiente entrada:**\n",
    "\n",
    "```\n",
    "tool,input  \n",
    "calculator,1933 - 1872  \n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Observa que agregamos dos cosas:\n",
    "\n",
    "1. Una herramienta `output` que el modelo debe usar cuando tenga la respuesta final. Nosotros la usaremos como señal para detener el bucle.\n",
    "2. El resultado de la herramienta en la iteración previa, simplemente con el nombre de la herramienta y su salida en texto. Esto permite que el LLM avance al siguiente paso en la interacción. En otras palabras, le estamos diciendo: “Aquí tienes los resultados que pediste, ¿qué quieres hacer ahora?”\n",
    "\n",
    "Continuamos con una tercera iteración:\n",
    "\n",
    "```\n",
    "tool,input  \n",
    "search,30th president of the United States  \n",
    "```\n",
    "\n",
    "Resultado del `search`:  \n",
    "> Calvin Coolidge (4 de julio de 1872 – 5 de enero de 1933)...\n",
    "\n",
    "```\n",
    "tool,input  \n",
    "calculator,1933 - 1872  \n",
    "```\n",
    "\n",
    "Resultado del `calculator`:  \n",
    "> 61\n",
    "\n",
    "```\n",
    "tool,input  \n",
    "output,61  \n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Con el resultado del `calculator`, el LLM ya tiene suficiente información para proporcionar la respuesta final, así que selecciona la herramienta `output` y escribe “61” como respuesta final.\n",
    "\n",
    "Esto es lo que hace tan útil a la arquitectura de agentes: se le da al modelo la *agencia* para decidir. Decide qué pasos tomar, cuándo avanzar y cuándo detenerse.\n",
    "\n",
    "Esta arquitectura, conocida como **ReAct**, fue propuesta por Shunyu Yao y colaboradores. El resto del capítulo explora cómo mejorar el rendimiento de esta arquitectura, motivado por el ejemplo del asistente de correos electrónicos del Capítulo 5.\n",
    "\n",
    "Pero primero, veamos cómo se ve la implementación básica de la arquitectura de agentes usando un modelo conversacional y LangGraph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171042f1-8a04-49a5-898e-d8a9a7882fbf",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Construyendo un Agente con LangGraph\n",
    "\n",
    "Para este ejemplo, necesitamos instalar dependencias adicionales para la herramienta de búsqueda que elegimos: DuckDuckGo. Para instalarla en Python:\n",
    "\n",
    "```bash\n",
    "pip install duckduckgo-search\n",
    "```\n",
    "\n",
    "Una vez hecho esto, pasemos al código para implementar la arquitectura del agente.\n",
    "\n",
    "Estamos utilizando dos herramientas en este ejemplo: una herramienta de búsqueda y una calculadora. Pero podrías agregar más o reemplazar las que usamos fácilmente. En el ejemplo de Python, también se muestra cómo crear una herramienta personalizada.\n",
    "\n",
    "Usamos dos funciones convenientes que vienen con LangGraph:\n",
    "\n",
    "- `ToolNode` actúa como un nodo en nuestro grafo; ejecuta las llamadas a herramientas solicitadas en el mensaje más reciente de la IA que se encuentra en el estado y devuelve un `ToolMessage` con los resultados de cada herramienta. También maneja excepciones que puedan surgir en las herramientas: si una herramienta falla, el error se convierte en un mensaje que se pasa al modelo LLM, el cual decidirá qué hacer con ese error.\n",
    "  \n",
    "- `tools_condition` funciona como una función de borde condicional. Analiza el mensaje más reciente generado por el modelo y decide si hay herramientas que ejecutar. Si es así, dirige el flujo hacia el nodo de herramientas. Si no hay herramientas que ejecutar, finaliza el grafo.\n",
    "\n",
    "Es importante notar que este grafo tiene un **bucle** entre los nodos del modelo y de las herramientas. Es decir, el propio modelo es quien decide cuándo terminar la ejecución, lo cual es una característica clave de la arquitectura de agentes. Siempre que se programe un bucle en LangGraph, probablemente se utilizará un borde condicional como este, ya que permite definir la condición de salida del bucle.\n",
    "\n",
    "Ahora veamos cómo se comporta con el ejemplo que vimos anteriormente:\n",
    "\n",
    "```python\n",
    "input = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\"¿Cuántos años tenía el 30º presidente de los Estados Unidos cuando murió?\")\n",
    "    ]\n",
    "}\n",
    "for c in graph.stream(input):\n",
    "    print(c)\n",
    "```\n",
    "\n",
    "### Recorrido del resultado:\n",
    "\n",
    "1. **Primero**, se ejecuta el nodo del modelo, que decide llamar a la herramienta `duckduckgo_search`. Como resultado, el borde condicional redirige la ejecución al nodo de herramientas.\n",
    "\n",
    "2. **Luego**, `ToolNode` ejecuta la herramienta de búsqueda y obtiene resultados que contienen directamente la respuesta: “Edad y año de fallecimiento: 5 de enero de 1933 (60 años)”.\n",
    "\n",
    "3. **Después**, se llama nuevamente al modelo, ahora con los resultados de la búsqueda como el mensaje más reciente, y este produce la respuesta final sin llamar a más herramientas. Por lo tanto, el borde condicional finaliza el grafo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88476ca6-4a08-4bda-b612-ba87f02bed43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "@tool\n",
    "def calculator(query: str) -> str:\n",
    "    \"\"\"Una calculadora simple. La entrada debe ser una expresión matemática.\"\"\"\n",
    "    return ast.literal_eval(query)\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "tools = [search, calculator]\n",
    "model = ChatOpenAI(temperature=0.1).bind_tools(tools)\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def model_node(state: State) -> State:\n",
    "    res = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": res}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"model\", model_node)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"model\")\n",
    "builder.add_conditional_edges(\"model\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"model\")\n",
    "\n",
    "graph = builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde5d7d5-111d-4419-93aa-2670fed0addb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Explicación del Código y el Flujo de Trabajo\n",
    "\n",
    "Este código implementa un flujo de trabajo que involucra un modelo de lenguaje (`ChatOpenAI`) y varias herramientas (como **DuckDuckGoSearchRun** y una calculadora personalizada). Vamos a desglosar cómo se integran las herramientas y cómo se establece un ciclo entre el modelo y las herramientas utilizando un grafo.\n",
    "\n",
    "#### 1. **Uso de herramientas con el modelo:**\n",
    "\n",
    "El código utiliza **`DuckDuckGoSearchRun`** como una herramienta de búsqueda, junto con una **calculadora** para realizar operaciones matemáticas. Estas herramientas son esenciales para que el modelo pueda interactuar con el entorno más allá de solo generar texto. Al asociar estas herramientas con el modelo de lenguaje, el modelo puede ejecutar funciones adicionales (como hacer una búsqueda o calcular una expresión) cuando sea necesario.\n",
    "\n",
    "```python\n",
    "search = DuckDuckGoSearchRun()  # Herramienta de búsqueda\n",
    "tools = [search, calculator]   # Lista de herramientas disponibles\n",
    "```\n",
    "\n",
    "**¿Qué hace esto?**\n",
    "- **`DuckDuckGoSearchRun`** es la herramienta de búsqueda que se usará para hacer consultas a través de DuckDuckGo.\n",
    "- **`tools`** es una lista que contiene tanto la herramienta de búsqueda como la calculadora. En este momento, el modelo puede acceder a estas herramientas cuando el flujo del grafo lo requiera.\n",
    "\n",
    "#### 2. **Vinculando las herramientas al modelo:**\n",
    "\n",
    "```python\n",
    "model = ChatOpenAI(temperature=0.1).bind_tools(tools)\n",
    "```\n",
    "\n",
    "**¿Qué hace esto?**\n",
    "- **`bind_tools(tools)`** es un método que asocia las herramientas definidas en la lista `tools` (que incluye el `DuckDuckGoSearchRun` y la calculadora) al modelo de lenguaje `ChatOpenAI`.\n",
    "- Esto le permite al modelo invocar estas herramientas en su proceso de generar respuestas, según lo determine el flujo del grafo.\n",
    "\n",
    "**Por qué es importante:**\n",
    "- Sin esta vinculación, el modelo no tendría acceso directo a las herramientas y no podría utilizarlas cuando el grafo lo requiera. `bind_tools` asegura que el modelo puede llamar a las herramientas dentro del ciclo de ejecución.\n",
    "\n",
    "#### 3. **Condicionales en el grafo:**\n",
    "\n",
    "```python\n",
    "builder.add_conditional_edges(\"model\", tools_condition)\n",
    "```\n",
    "\n",
    "**¿Qué hace esto?**\n",
    "- **`add_conditional_edges`** agrega un borde (o \"edge\") condicional entre el nodo `\"model\"` y los nodos de herramientas.\n",
    "- **`tools_condition`** es una función que determina si el modelo necesita ejecutar alguna herramienta (como la búsqueda o la calculadora). Si el modelo indica que debe usar alguna de las herramientas, el grafo llevará el flujo de ejecución al nodo de herramientas.\n",
    "\n",
    "**¿Por qué es importante?**\n",
    "- Esta función permite que el flujo del grafo sea dinámico. Solo se ejecutan las herramientas cuando el modelo las necesita, y esto se decide mediante la condición definida en `tools_condition`. Así, el grafo no ejecuta herramientas innecesarias, manteniendo el flujo eficiente.\n",
    "\n",
    "#### 4. **Bucle entre herramientas y modelo:**\n",
    "\n",
    "```python\n",
    "builder.add_edge(\"tools\", \"model\")\n",
    "```\n",
    "\n",
    "**¿Qué hace esto?**\n",
    "- Este borde conecta el nodo de herramientas (`\"tools\"`) de vuelta al nodo del modelo (`\"model\"`).\n",
    "- **¿Por qué?** Esto permite que el flujo regrese al nodo del modelo después de ejecutar alguna herramienta, como realizar una búsqueda o calcular algo. De esta manera, el modelo puede tomar los resultados de la herramienta y generar una nueva respuesta.\n",
    "\n",
    "**¿Por qué es importante?**\n",
    "- Esta conexión establece un ciclo entre los nodos del modelo y las herramientas. El flujo vuelve al modelo después de cada uso de las herramientas para asegurar que el modelo pueda procesar y generar una respuesta con la nueva información obtenida de las herramientas. \n",
    "- Este ciclo puede repetirse varias veces, dependiendo de si el modelo necesita más interacciones con las herramientas o si puede generar la respuesta final.\n",
    "\n",
    "#### Resumen del Flujo\n",
    "\n",
    "1. **Inicio del grafo**: El flujo comienza en el nodo `\"model\"`, donde el modelo genera una respuesta.\n",
    "2. **Condición para herramientas**: Si el modelo necesita usar alguna herramienta, el flujo se mueve al nodo `\"tools\"`, donde se ejecutan las herramientas necesarias.\n",
    "3. **Volver al modelo**: Después de ejecutar la herramienta, el flujo regresa al nodo `\"model\"`, y el modelo utiliza los resultados de la herramienta para generar una nueva respuesta.\n",
    "4. **Repetir o finalizar**: Este ciclo se repite hasta que el modelo decide que no necesita más herramientas y se puede generar la respuesta final.\n",
    "\n",
    "Este diseño permite que el modelo interactúe dinámicamente con el entorno, haciendo uso de herramientas cuando sea necesario y manteniendo el flujo de ejecución eficiente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b3e9263-f3ba-421d-8419-2f98f7eeebce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'messages': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_dZeiPIcICUwM8MWS8owQD0j2', 'function': {'arguments': '{\"query\":\"Age of 30th president of the United States at death\"}', 'name': 'duckduckgo_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 126, 'total_tokens': 155, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BNon3L57wrYZ5kcOmvAfIUODFykEm', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a82c82b4-2fc2-46bf-88f3-6c58d7f91aac-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Age of 30th president of the United States at death'}, 'id': 'call_dZeiPIcICUwM8MWS8owQD0j2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 126, 'output_tokens': 29, 'total_tokens': 155, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n",
      "{'tools': {'messages': [ToolMessage(content=\"Calvin Coolidge (born John Calvin Coolidge Jr.; [1] / ˈ k uː l ɪ dʒ / KOOL-ij; July 4, 1872 - January 5, 1933) was the 30th president of the United States, serving from 1923 to 1929.A Republican lawyer from Massachusetts, he previously served as the 29th vice president from 1921 to 1923 under President Warren G. Harding, and as the 48th governor of Massachusetts from 1919 to 1921. The White House, official residence of the president of the United States. The president of the United States is the head of state and head of government of the United States, [1] indirectly elected to a four-year term via the Electoral College. [2] Under the U.S. Constitution, the officeholder leads the executive branch of the federal government and is the commander-in-chief of the United ... Calvin Coolidge was the 30th president of the United States (1923-29). Coolidge acceded to the presidency after the death in office of Warren G. Harding, just as the Harding scandals were coming to light. He restored integrity to the executive branch while continuing Harding's conservative pro-business policies. John Calvin Coolidge Jr. was the 30th President of the United States (1923-29). A Republican lawyer from Vermont, Coolidge worked his way up the ladder of Massachusetts state politics, eventually becoming governor of that state. ... (September 7, 1906 - May 31, 2000) and Calvin Jr. (April 13, 1908 - July 7, 1924). Calvin's death at age 16 ... The first table below charts the age of each president of the United States at the time of their presidential inauguration (first inauguration if elected to multiple and consecutive terms), upon leaving office, and at the time of death. Where the president is still living, their lifespan and post-presidency timespan are calculated through April 11, 2025.\", name='duckduckgo_search', id='fc002ae7-1230-4000-b127-9ab8ed1a8bf6', tool_call_id='call_dZeiPIcICUwM8MWS8owQD0j2')]}}\n",
      "{'model': {'messages': AIMessage(content='El 30° presidente de los Estados Unidos, Calvin Coolidge, murió a la edad de 60 años.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 592, 'total_tokens': 619, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BNon5eT8o9WMugT58TlkKPV4uV8qE', 'finish_reason': 'stop', 'logprobs': None}, id='run-f62dc9b4-96ca-47be-bb9d-ac7be15aedd8-0', usage_metadata={'input_tokens': 592, 'output_tokens': 27, 'total_tokens': 619, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso:\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "input = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            \"¿Cuántos años tenía el 30° presidente de los Estados Unidos cuando murió?\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "for step in graph.stream(input):\n",
    "    print(step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18811ec-0161-40a9-8bf4-435eee95bd49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install langchain-community duckduckgo-search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0fa1d1-67ae-406c-9131-710cfc5d2bf7",
   "metadata": {},
   "source": [
    "Aquí hay algunas cosas a notar:\n",
    "\n",
    "Estamos utilizando dos herramientas en este ejemplo: una herramienta de búsqueda y una herramienta de calculadora, pero podrías agregar fácilmente más o reemplazar las que usamos. En el ejemplo de Python, también puedes ver un ejemplo de cómo crear una herramienta personalizada.\n",
    "\n",
    "Hemos utilizado dos funciones de conveniencia que vienen con LangGraph. ToolNode sirve como un nodo en nuestro grafo; ejecuta las llamadas a las herramientas solicitadas en el último mensaje de IA encontrado en el estado y devuelve un ToolMessage con los resultados de cada una. ToolNode también maneja las excepciones que pueden ser levantadas por las herramientas, utilizando el mensaje de error para construir un ToolMessage que luego se pasa al LLM, el cual puede decidir qué hacer con el error.\n",
    "\n",
    "tools_condition sirve como una función de borde condicional que observa el último mensaje de IA en el estado y redirige al nodo de herramientas si hay alguna herramienta que ejecutar. De lo contrario, termina el grafo.\n",
    "\n",
    "Finalmente, observa que este grafo hace un ciclo entre los nodos del modelo y las herramientas. Es decir, el modelo mismo se encarga de decidir cuándo terminar el cálculo, lo cual es un atributo clave de la arquitectura del agente. Siempre que codifiquemos un ciclo en LangGraph, probablemente querremos usar un borde condicional, ya que esto te permite definir la condición de parada para cuando el grafo debe salir del ciclo y dejar de ejecutarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1138b9e7-4b15-4937-9343-37e60fb71e06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The output:\n",
      "\n",
      "\n",
      "Step: model\n",
      "{\n",
      "    \"model\": {\n",
      "        \"messages\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "                \"tool_calls\": [\n",
      "                    {\n",
      "                        \"id\": \"call_gzq6TjuwPUA9W0eoLOZNzWPr\",\n",
      "                        \"function\": {\n",
      "                            \"arguments\": \"{\\\"query\\\":\\\"30th president of the United States age at death\\\"}\",\n",
      "                            \"name\": \"duckduckgo_search\"\n",
      "                        },\n",
      "                        \"type\": \"function\"\n",
      "                    }\n",
      "                ],\n",
      "                \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "                \"token_usage\": {\n",
      "                    \"completion_tokens\": 27,\n",
      "                    \"prompt_tokens\": 118,\n",
      "                    \"total_tokens\": 145,\n",
      "                    \"completion_tokens_details\": {\n",
      "                        \"accepted_prediction_tokens\": 0,\n",
      "                        \"audio_tokens\": 0,\n",
      "                        \"reasoning_tokens\": 0,\n",
      "                        \"rejected_prediction_tokens\": 0\n",
      "                    },\n",
      "                    \"prompt_tokens_details\": {\n",
      "                        \"audio_tokens\": 0,\n",
      "                        \"cached_tokens\": 0\n",
      "                    }\n",
      "                },\n",
      "                \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "                \"system_fingerprint\": null,\n",
      "                \"id\": \"chatcmpl-BNou1XWjA17c3MJGs7epwEx2FEdkr\",\n",
      "                \"finish_reason\": \"tool_calls\",\n",
      "                \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"name\": null,\n",
      "            \"id\": \"run-a3a81081-f229-4e52-8799-8740a0e42068-0\",\n",
      "            \"example\": false,\n",
      "            \"tool_calls\": [\n",
      "                {\n",
      "                    \"name\": \"duckduckgo_search\",\n",
      "                    \"args\": {\n",
      "                        \"query\": \"30th president of the United States age at death\"\n",
      "                    },\n",
      "                    \"id\": \"call_gzq6TjuwPUA9W0eoLOZNzWPr\",\n",
      "                    \"type\": \"tool_call\"\n",
      "                }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"usage_metadata\": {\n",
      "                \"input_tokens\": 118,\n",
      "                \"output_tokens\": 27,\n",
      "                \"total_tokens\": 145,\n",
      "                \"input_token_details\": {\n",
      "                    \"audio\": 0,\n",
      "                    \"cache_read\": 0\n",
      "                },\n",
      "                \"output_token_details\": {\n",
      "                    \"audio\": 0,\n",
      "                    \"reasoning\": 0\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_675/669740557.py:55: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  return msg.dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: tools\n",
      "{\n",
      "    \"tools\": {\n",
      "        \"messages\": [\n",
      "            {\n",
      "                \"content\": \"Calvin Coolidge (born John Calvin Coolidge Jr.; [1] / \\u02c8 k u\\u02d0 l \\u026a d\\u0292 / KOOL-ij; July 4, 1872 - January 5, 1933) was the 30th president of the United States, serving from 1923 to 1929.A Republican lawyer from Massachusetts, he previously served as the 29th vice president from 1921 to 1923 under President Warren G. Harding, and as the 48th governor of Massachusetts from 1919 to 1921. Calvin Coolidge was the 30th president of the United States (1923-29). Coolidge acceded to the presidency after the death in office of Warren G. Harding, just as the Harding scandals were coming to light. He restored integrity to the executive branch while continuing Harding's conservative pro-business policies. The White House, official residence of the president of the United States. The president of the United States is the head of state and head of government of the United States, [1] indirectly elected to a four-year term via the Electoral College. [2] Under the U.S. Constitution, the officeholder leads the executive branch of the federal government and is the commander-in-chief of the United ... Consequently, his actions during the upheaval paved the way for his nomination as vice president in 1920, illustrating his emergence as a key player in the Republican Party. Vice Presidency and Presidential Duties. Calvin Coolidge served as the 30th Vice President of the United States from 1921 to 1923 under President Warren G. Harding. John Calvin Coolidge Jr. was the 30th President of the United States (1923-29). A Republican lawyer from Vermont, Coolidge worked his way up the ladder of Massachusetts state politics, eventually becoming governor of that state. ... (September 7, 1906 - May 31, 2000) and Calvin Jr. (April 13, 1908 - July 7, 1924). Calvin's death at age 16 ...\",\n",
      "                \"additional_kwargs\": {},\n",
      "                \"response_metadata\": {},\n",
      "                \"type\": \"tool\",\n",
      "                \"name\": \"duckduckgo_search\",\n",
      "                \"id\": \"a7c861c9-4fb6-4e5a-8a94-ebedda6921fa\",\n",
      "                \"tool_call_id\": \"call_gzq6TjuwPUA9W0eoLOZNzWPr\",\n",
      "                \"artifact\": null,\n",
      "                \"status\": \"success\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_675/669740557.py:55: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  return msg.dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: model\n",
      "{\n",
      "    \"model\": {\n",
      "        \"messages\": {\n",
      "            \"content\": \"Calvin Coolidge, the 30th president of the United States, died on January 5, 1933. He was born on July 4, 1872. To calculate his age at the time of his death, we need to subtract his birth year from the year of his death:\\n\\n1933 (year of death) - 1872 (birth year) = 61 years old\\n\\nCalvin Coolidge was 61 years old when he died.\",\n",
      "            \"additional_kwargs\": {\n",
      "                \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "                \"token_usage\": {\n",
      "                    \"completion_tokens\": 98,\n",
      "                    \"prompt_tokens\": 584,\n",
      "                    \"total_tokens\": 682,\n",
      "                    \"completion_tokens_details\": {\n",
      "                        \"accepted_prediction_tokens\": 0,\n",
      "                        \"audio_tokens\": 0,\n",
      "                        \"reasoning_tokens\": 0,\n",
      "                        \"rejected_prediction_tokens\": 0\n",
      "                    },\n",
      "                    \"prompt_tokens_details\": {\n",
      "                        \"audio_tokens\": 0,\n",
      "                        \"cached_tokens\": 0\n",
      "                    }\n",
      "                },\n",
      "                \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "                \"system_fingerprint\": null,\n",
      "                \"id\": \"chatcmpl-BNou2cTXFIkPnqn1V5TpCIFQR9Qa4\",\n",
      "                \"finish_reason\": \"stop\",\n",
      "                \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"name\": null,\n",
      "            \"id\": \"run-1f6b9c60-0da2-405d-aa0a-9033a82734d8-0\",\n",
      "            \"example\": false,\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"usage_metadata\": {\n",
      "                \"input_tokens\": 584,\n",
      "                \"output_tokens\": 98,\n",
      "                \"total_tokens\": 682,\n",
      "                \"input_token_details\": {\n",
      "                    \"audio\": 0,\n",
      "                    \"cache_read\": 0\n",
      "                },\n",
      "                \"output_token_details\": {\n",
      "                    \"audio\": 0,\n",
      "                    \"reasoning\": 0\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_675/669740557.py:55: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  return msg.dict()\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "from typing import Annotated, TypedDict\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# Herramienta de calculadora\n",
    "@tool\n",
    "def calculator(query: str) -> str:\n",
    "    \"\"\"A simple calculator tool. Input should be a mathematical expression.\"\"\"\n",
    "    return str(ast.literal_eval(query))\n",
    "\n",
    "# Herramientas disponibles\n",
    "search = DuckDuckGoSearchRun()\n",
    "tools = [search, calculator]\n",
    "model = ChatOpenAI(temperature=0.1).bind_tools(tools)\n",
    "\n",
    "# Estado del grafo\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Nodo del modelo\n",
    "def model_node(state: State) -> State:\n",
    "    res = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": res}\n",
    "\n",
    "# Grafo\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"model\", model_node)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"model\")\n",
    "builder.add_conditional_edges(\"model\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"model\")\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "input = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            \"¿Cuántos años tenía el 30° presidente de los Estados Unidos cuando murió?\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Función para serializar mensajes individuales\n",
    "def serialize_message(msg):\n",
    "    if isinstance(msg, BaseMessage):\n",
    "        return msg.dict()\n",
    "    elif isinstance(msg, tuple) and isinstance(msg[1], BaseMessage):\n",
    "        return { \"name\": msg[0], **msg[1].dict() }\n",
    "    else:\n",
    "        return str(msg)\n",
    "\n",
    "\n",
    "# Ejecutar el agente y mostrar los pasos\n",
    "print(\"\\nThe output:\\n\")\n",
    "for step in graph.stream(input_data):\n",
    "    for key, value in step.items():\n",
    "        print(f\"\\nStep: {key}\")\n",
    "        if \"messages\" in value:\n",
    "            msgs = value[\"messages\"]\n",
    "            if isinstance(msgs, list):\n",
    "                serialized = [serialize_message(m) for m in msgs]\n",
    "            else:\n",
    "                serialized = serialize_message(msgs)\n",
    "            print(json.dumps({key: {\"messages\": serialized}}, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27695b40-a959-4189-b7d0-252f35c04b59",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Llamando siempre a una herramienta primero**  \n",
    "En la arquitectura estándar de agentes, el LLM siempre es llamado para decidir qué herramienta usar a continuación. Este enfoque tiene una ventaja clara: le da al LLM una flexibilidad total para adaptar el comportamiento de la aplicación a cada consulta del usuario. Pero esta flexibilidad tiene un costo: la imprevisibilidad. Por ejemplo, si tú, como desarrollador de la aplicación, sabes que la herramienta de búsqueda siempre debe ser llamada primero, eso en realidad puede beneficiar tu aplicación:\n",
    "\n",
    "- Reducirá la latencia general, ya que se omitirá la primera llamada al LLM que solo generaría esa solicitud para usar la herramienta de búsqueda.\n",
    "- Evitará que el LLM decida erróneamente que no necesita llamar a la herramienta de búsqueda para algunas consultas.\n",
    "\n",
    "Por otro lado, si tu aplicación no tiene una regla clara como “siempre debes llamar a esta herramienta primero”, imponer esa restricción en realidad podría empeorar la aplicación.\n",
    "\n",
    "Veamos cómo se hace esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "352ce4c3-aa78-4bf4-aa66-a25b9828bcd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "### Código en Python\n",
    "import ast\n",
    "from typing import Annotated, TypedDict\n",
    "from uuid import uuid4\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.messages import AIMessage, ToolCall\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "@tool\n",
    "def calculator(query: str) -> str:\n",
    "    \"\"\"Una herramienta de calculadora simple. El input debe ser una expresión matemática.\"\"\"\n",
    "    return ast.literal_eval(query)\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "tools = [search, calculator]\n",
    "model = ChatOpenAI(temperature=0.1).bind_tools(tools)\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def model_node(state: State) -> State:\n",
    "    res = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": res}\n",
    "\n",
    "def first_model(state: State) -> State:\n",
    "    query = state[\"messages\"][-1].content\n",
    "    search_tool_call = ToolCall(\n",
    "        name=\"duckduckgo_search\", args={\"query\": query}, id=uuid4().hex\n",
    "    )\n",
    "    return {\"messages\": AIMessage(content=\"\", tool_calls=[search_tool_call])}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"first_model\", first_model)\n",
    "builder.add_node(\"model\", model_node)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"first_model\")\n",
    "builder.add_edge(\"first_model\", \"tools\")\n",
    "builder.add_conditional_edges(\"model\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"model\")\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9697f0cd-0d9f-4ae2-92de-85c6f243a584",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Observa las diferencias con respecto a la sección anterior:**\n",
    "\n",
    "Ahora, comenzamos todas las invocaciones llamando a `first_model`, que no llama a ningún modelo de lenguaje. Solo crea una llamada a la herramienta de búsqueda, usando el mensaje del usuario tal cual como consulta. La arquitectura anterior habría hecho que el LLM generara esta llamada a herramienta (u otra respuesta que considerara mejor).\n",
    "\n",
    "Después de eso, pasamos a `tools`, que es idéntico al ejemplo anterior, y de ahí procedemos al nodo del agente como antes.\n",
    "\n",
    "Ahora veamos un ejemplo de salida, usando la misma consulta que antes:\n",
    "\n",
    "---\n",
    "\n",
    "### Código en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5373bfc-5918-42f1-89f5-4562a4cecdcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_model': {'messages': AIMessage(content='', additional_kwargs={}, response_metadata={}, id='ebc360bd-7d62-4120-8e1d-125b07e41f9b', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'How old was the 30th president of the United States \\n            when he died?'}, 'id': '5f64ab25e4274ef4a7cbca819f375572', 'type': 'tool_call'}])}}\n",
      "{'tools': {'messages': [ToolMessage(content='Calvin Coolidge (born John Calvin Coolidge Jr.; [1] / ˈ k uː l ɪ dʒ / KOOL-ij; July 4, 1872 - January 5, 1933) was the 30th president of the United States, serving from 1923 to 1929.A Republican lawyer from Massachusetts, he previously served as the 29th vice president from 1921 to 1923 under President Warren G. Harding, and as the 48th governor of Massachusetts from 1919 to 1921. The White House, official residence of the president of the United States. The president of the United States is the head of state and head of government of the United States, [1] indirectly elected to a four-year term via the Electoral College. [2] Under the U.S. Constitution, the officeholder leads the executive branch of the federal government and is the commander-in-chief of the United ... Calvin Coolidge was the 30th president of the United States (1923-29). Coolidge acceded to the presidency after the death in office of Warren G. Harding, just as the Harding scandals were coming to light. ... 1872, Plymouth, Vermont, U.S.—died January 5, 1933, Northampton, Massachusetts) was the 30th president of the United States (1923 ... John Calvin Coolidge, Jr. (July 4, 1872 - January 5, 1933) was the 30th President of the United States (1923-1929). A lawyer from Vermont, Coolidge worked his way up the ladder of Massachusetts state politics, eventually becoming governor of that state. Calvin Coolidge served as the 30th president of the United States from 1923 - 1929. Prior to the presidency, Coolidge was a lawyer and politician. He took over as president following the death of Warren Harding in 1923. Coolidge died in Northampton, MA in 1933.', name='duckduckgo_search', id='0f64d057-381f-4013-be2f-a836e8c1c8ac', tool_call_id='5f64ab25e4274ef4a7cbca819f375572')]}}\n",
      "{'model': {'messages': AIMessage(content='Calvin Coolidge, the 30th president of the United States, was born on July 4, 1872, and died on January 5, 1933. To calculate his age at the time of his death, we can subtract his birth year from his death year:\\n\\n1933 (death year) - 1872 (birth year) = 61 years old\\n\\nCalvin Coolidge was 61 years old when he died.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 592, 'total_tokens': 686, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BNpdprMJHQDgfYsBJX0uHPO2xbP8r', 'finish_reason': 'stop', 'logprobs': None}, id='run-6bf71de8-66fd-4eee-a7ba-bd0695afe1fb-0', usage_metadata={'input_tokens': 592, 'output_tokens': 94, 'total_tokens': 686, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\"\"\"How old was the 30th president of the United States \n",
    "            when he died?\"\"\")\n",
    "    ]\n",
    "}\n",
    "for c in graph.stream(input):\n",
    "    print(c)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77152fc-5f90-4d75-a768-04a9a4035ed8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Esta vez, nos saltamos la llamada inicial al LLM.**  \n",
    "Primero fuimos al nodo `first_model`, que directamente devolvió una llamada a la herramienta de búsqueda.  \n",
    "De ahí seguimos el flujo anterior —es decir, ejecutamos la herramienta de búsqueda y finalmente regresamos al nodo del modelo para generar la respuesta final.\n",
    "\n",
    "---\n",
    "\n",
    "A continuación, veamos qué puedes hacer cuando tienes **muchas herramientas** que deseas poner a disposición del LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8280620e-582d-410f-9157-99ccae7c206f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Tratando con Muchas Herramientas\n",
    "\n",
    "Los modelos de lenguaje (LLMs) no son perfectos y tienden a tener dificultades cuando se les presentan muchas opciones o demasiada información en un mismo prompt.  \n",
    "Estas limitaciones también afectan su capacidad para planear cuál debería ser la siguiente acción a tomar.  \n",
    "Cuando se les da muchas herramientas (por ejemplo, más de 10), su rendimiento al elegir la herramienta correcta empieza a disminuir.\n",
    "\n",
    "#### ¿La solución?\n",
    "\n",
    "Reducir el número de herramientas entre las que el LLM puede elegir.  \n",
    "Pero, ¿qué pasa si realmente tienes muchas herramientas que quieres usar dependiendo del tipo de consulta?\n",
    "\n",
    "Una solución elegante es usar un paso de **RAG (Recuperación Augmentada con Generación)** para **preseleccionar** las herramientas más relevantes para la consulta actual y luego alimentar al LLM solo con ese subconjunto, en lugar de todo el arsenal de herramientas.  \n",
    "\n",
    "Esto también ayuda a reducir el costo de invocación del LLM (los modelos comerciales cobran con base en la longitud del prompt y la respuesta).\n",
    "\n",
    "**Nota:** este paso RAG añade latencia, así que solo deberías implementarlo cuando observes que el rendimiento cae después de agregar muchas herramientas.\n",
    "\n",
    "---\n",
    "\n",
    "### Código en Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3419a7ec-2156-4170-85e1-292f3734c4d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'description'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_675/3619316190.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'description'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5978bd72-0ddf-48c8-b31a-8deca1c54337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.vectorstores.in_memory import InMemoryVectorStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "@tool\n",
    "def calculator(query: str) -> str:\n",
    "    \"\"\"A simple calculator tool. Input should be a mathematical expression.\"\"\"\n",
    "    return ast.literal_eval(query)\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "tools = [search, calculator]\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "model = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "tools_retriever = InMemoryVectorStore.from_documents(\n",
    "    [Document(tool.description, metadata={\"name\": tool.name}) for tool in tools],\n",
    "    embeddings,\n",
    ").as_retriever()\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    selected_tools: list[str]\n",
    "\n",
    "def model_node(state: State) -> State:\n",
    "    selected_tools = [\n",
    "        tool for tool in tools if tool.name in state[\"selected_tools\"]\n",
    "    ]\n",
    "    res = model.bind_tools(selected_tools).invoke(state[\"messages\"])\n",
    "    return {\"messages\": res}\n",
    "\n",
    "def select_tools(state: State) -> State:\n",
    "    query = state[\"messages\"][-1].content\n",
    "    tool_docs = tools_retriever.invoke(query)\n",
    "    return {\"selected_tools\": [doc.metadata[\"name\"] for doc in tool_docs]}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"select_tools\", select_tools)\n",
    "builder.add_node(\"model\", model_node)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"select_tools\")\n",
    "builder.add_edge(\"select_tools\", \"model\")\n",
    "builder.add_conditional_edges(\"model\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"model\")\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b12ad7-3402-4b04-b1cf-dd99104e4fc9",
   "metadata": {},
   "source": [
    "**NOTA:**  \n",
    "Esto es muy similar a la arquitectura de agentes regular.  \n",
    "La única diferencia es que **hacemos una parada en el nodo `select_tools`** antes de entrar al ciclo del agente como tal.  \n",
    "Después de eso, funciona igual que la arquitectura de agentes que vimos antes.\n",
    "\n",
    "Veamos un ejemplo de salida para la misma consulta anterior:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94db00cd-50d6-41ad-9291-454375f8a220",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre: calculator\n",
      "Descripción: Una calculadora simple. La entrada debe ser una expresión matemática.\n",
      "----------------------------------------\n",
      "Nombre: greet\n",
      "Descripción: Devuelve un saludo amistoso.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# Definir herramientas\n",
    "@tool\n",
    "def calculator(query: str) -> str:\n",
    "    \"\"\"Una calculadora simple. La entrada debe ser una expresión matemática.\"\"\"\n",
    "    return str(eval(query))\n",
    "\n",
    "@tool\n",
    "def greet(name: str) -> str:\n",
    "    \"\"\"Devuelve un saludo amistoso.\"\"\"\n",
    "    return f\"Hola, {name}!\"\n",
    "\n",
    "# Lista de herramientas\n",
    "tools = [calculator, greet]\n",
    "\n",
    "# Mostrar nombre y descripción de cada herramienta\n",
    "for tool in tools:\n",
    "    print(f\"Nombre: {tool.name}\")\n",
    "    print(f\"Descripción: {tool.description}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e7bc574-afe8-43b6-9780-d80cc6169187",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'select_tools': {'selected_tools': ['duckduckgo_search', 'calculator']}}\n",
      "{'model': {'messages': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_rCd89Je3KZPTHyTwHfIlZKRX', 'function': {'arguments': '{\"query\":\"30th president of the United States age at death\"}', 'name': 'duckduckgo_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 120, 'total_tokens': 147, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BNpoFhrWlrY2CsnTqwEr1KoxehkRJ', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e551b605-e423-417f-92af-87fb5601fddb-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': '30th president of the United States age at death'}, 'id': 'call_rCd89Je3KZPTHyTwHfIlZKRX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 120, 'output_tokens': 27, 'total_tokens': 147, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n",
      "{'tools': {'messages': [ToolMessage(content=\"Calvin Coolidge (born John Calvin Coolidge Jr.; [1] / ˈkuːlɪdʒ / KOOL-ij; July 4, 1872 - January 5, 1933) was the 30th president of the United States, serving from 1923 to 1929. A Republican lawyer from Massachusetts, he previously served as the 29th vice president from 1921 to 1923 under President Warren G. Harding, and as the 48th governor of Massachusetts from 1919 to 1921. Coolidge ... Calvin Coolidge was the 30th president of the United States (1923-29). He acceded to the presidency after the death in office of , just as the Harding scandals were coming to light. He restored integrity to the executive branch of the federal government while continuing the conservative pro-business policies of his predecessor. The White House, official residence of the president of the United States The president of the United States is the head of state and head of government of the United States, [1] indirectly elected to a four-year term via the Electoral College. [2] Under the U.S. Constitution, the officeholder leads the executive branch of the federal government and is the commander-in-chief of the United ... Who is Calvin Coolidge? Calvin Coolidge was the 30th president of the United States, known for his quiet demeanor and remarkable economic policies during the 1920s. Born on July 4, 1872, in Plymouth Notch, Vermont, he rose through various local and state positions, ultimately becoming the Vice President under Warren G. Harding. Following Harding's death in 1923, Coolidge assumed the presidency ... The first table below charts the age of each president of the United States at the time of their presidential inauguration (first inauguration if elected to multiple and consecutive terms), upon leaving office, and at the time of death. Where the president is still living, their lifespan and post-presidency timespan are calculated through April 11, 2025.\", name='duckduckgo_search', id='27b079fb-42bf-4ece-86bd-507c87432150', tool_call_id='call_rCd89Je3KZPTHyTwHfIlZKRX')]}}\n",
      "{'model': {'messages': AIMessage(content='Calvin Coolidge, the 30th president of the United States, was born on July 4, 1872, and died on January 5, 1933. To calculate his age at the time of his death, we can subtract his birth year from his death year. \\n\\nAge at death = Death year - Birth year\\nAge at death = 1933 - 1872\\nAge at death = 61 years\\n\\nCalvin Coolidge was 61 years old when he died.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 105, 'prompt_tokens': 579, 'total_tokens': 684, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BNpoHd9escwi3LSCHhjQXomklSjWU', 'finish_reason': 'stop', 'logprobs': None}, id='run-ce077888-a212-4c1f-ae4b-739422b14d70-0', usage_metadata={'input_tokens': 579, 'output_tokens': 105, 'total_tokens': 684, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\"\"\"How old was the 30th president of the United States when \n",
    "            he died?\"\"\")\n",
    "    ]\n",
    "}\n",
    "for c in graph.stream(input):\n",
    "    print(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f169688-c384-40c2-aefe-9bdc6e1829b5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Observa cómo lo primero que hicimos fue **consultar al recuperador** (`retriever`) para obtener las herramientas **más relevantes** para la consulta actual del usuario.  \n",
    "Luego, procedimos con la **arquitectura de agente regular**.\n",
    "\n",
    "---\n",
    "\n",
    "### Resumen\n",
    "\n",
    "Este capítulo introdujo el concepto de **agencia** y discutió lo necesario para hacer que una aplicación basada en un LLM sea **agentiva**:  \n",
    "darle al LLM la **capacidad de decidir entre múltiples opciones**, usando información externa.\n",
    "\n",
    "Recorrimos la arquitectura estándar de un agente construida con **LangGraph**, y exploramos dos extensiones útiles:\n",
    "\n",
    "- **Cómo llamar siempre primero a una herramienta específica**.\n",
    "- **Cómo manejar múltiples herramientas** de forma eficiente.\n",
    "\n",
    "El **Capítulo 7** explorará más extensiones para esta arquitectura de agentes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b18ddbb-9f71-45f7-a203-50bc86d903af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
